# -*- coding: utf-8 -*-
"""Cs-Gr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tSmDFtgEWPXz74Zymb0dCLnr61Tu_deM

#Importar do drive

###Importações
"""

!pip install python-dateutil

from google.colab import drive
drive.mount('/content/drive')

import os
import datetime 
import pandas as pd
import numpy as np
from dateutil.relativedelta import relativedelta


from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)
client = gspread.authorize(creds)
import locale
import calendar
import math

import matplotlib.pyplot as plt
from dateutil import tz
import pytz

"""###Tratar data com horário Brasil"""

IST = pytz.timezone('America/Sao_Paulo') 
# print("UTC in Default Format : ",  
#       datetime.now(UTC)) 
data_atual = datetime.datetime.now(IST)
data_atual=data_atual.strftime('%m/%Y')



"""##Selecionando o último arquivo da pasta Revisão EXECUTIVA-PROPOSTAS"""

caminho="/content/drive/Othercomputers/Meu laptop/Revisão executiva"
caminho1="/content/drive/Othercomputers/Meu laptop/Controle/Planilha controle.xlsx"
lista_arquivos= os.listdir(caminho)
lista_datas= []
for arquivo in lista_arquivos:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho}/{arquivo}")
  lista_datas.append((data, arquivo))

lista_datas.sort(reverse=True)
ultimo_arquivo= lista_datas[0]
arquivo1=ultimo_arquivo[1]

arquivo1

"""##Selecionando o último arquivo da pasta SIMULAÇÕES"""

caminho4='/content/drive/Othercomputers/Meu laptop/SIMULAÇÕES'

lista_arquivos4= os.listdir(caminho4)
lista_datas4= []
for arquivo in lista_arquivos4:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho4}/{arquivo}")
  lista_datas4.append((data, arquivo))

lista_datas4.sort(reverse=True)
ultimo_arquivo4= lista_datas4[0]
arquivo4=ultimo_arquivo4[1]

arquivo1

"""##Buscando arquivos das questions 1402,303 relacionados as informações de todas as empresas 

"""

caminho2='/content/drive/Othercomputers/Meu laptop/Todas as empresas'
caminho3='/content/drive/Othercomputers/Meu laptop/Funcionarios por cnpj'
lista_arquivos1= os.listdir(caminho2)
lista_datas1= []
for arquivo in lista_arquivos1:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho2}/{arquivo}")
  lista_datas1.append((data, arquivo))

lista_datas1.sort(reverse=True)
ultimo_arquivo1= lista_datas1[0]
arquivo2=ultimo_arquivo1[1]

lista_arquivos2= os.listdir(caminho3)
lista_datas2= []
for arquivo in lista_arquivos2:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho3}/{arquivo}")
  lista_datas2.append((data, arquivo))

lista_datas2.sort(reverse=True)
ultimo_arquivo2= lista_datas2[0]
arquivo3=ultimo_arquivo2[1]

"""##Buscar dados revisão executiva- rejeição"""

caminho5='/content/drive/Othercomputers/Meu laptop/Revisão executiva- Rejeitadas'
lista_arquivos5= os.listdir(caminho5)
lista_datas5= []
for arquivo in lista_arquivos5:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho5}/{arquivo}")
  lista_datas5.append((data, arquivo))

lista_datas5.sort(reverse=True)
ultimo_arquivo5= lista_datas5[0]
arquivo5=ultimo_arquivo5[1]

"""##Simulações com valor"""

caminho10='/content/drive/Othercomputers/Meu laptop/Simulações com valor- xlsx'
lista_arquivos10= os.listdir(caminho10)
lista_datas10= []
for arquivo in lista_arquivos10:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho10}/{arquivo}")
  lista_datas10.append((data, arquivo))

lista_datas10.sort(reverse=True)
ultimo_arquivo10= lista_datas10[0]
arquivo10=ultimo_arquivo10[1]

"""##Calculando Dias uteis do mês"""

import holidays
data_hoje=datetime.datetime.now(IST)
dia = data_hoje
ano=dia.strftime('%Y')
ano=int(ano)
mes=dia.strftime('%m')
mes=int(mes)
dia=dia.strftime('%d')
dia=int(dia)
monthRange = calendar.monthrange(ano,mes)
qtd_dia_mes=int(monthRange[1])
feriados= holidays.Brazil()
dia1=str(1)
inicio_mes=dia1+'/'+str(mes)+'/'+str(ano)
fim_mes=str(qtd_dia_mes)+'/'+str(mes)+'/'+str(ano)
cont=0
##if data_hoje != feriados & dia_semana!='6' or '7':
def iterdates(date1, date2):
    one_day = datetime.timedelta(days = 1)
    current = date1
    while current <=date2:
        yield current
        current += one_day

date = datetime.datetime.strptime(inicio_mes, '%d/%m/%Y').date()
date2 = datetime.datetime.strptime(fim_mes, '%d/%m/%Y').date()
f=0
for d in iterdates(date, date2):
    if d.weekday() not in (5, 6):
      f=f+1

#####################################################
for feriado in feriados[date:date2] :
    if feriado.weekday()==(6 or 5):
      cont=cont
    else: cont=cont+1
    

Dias_uteis=f-cont
Dias_uteis

"""##Calculando dias úteis até a data hoje"""

##Dias úteis até a data de hoje
feriados_atual= holidays.Brazil()
dia1=str(1)
i=dia1+'/'+str(mes)+'/'+str(ano)
a=data_hoje
a=a.strftime('%d/%m/%Y')
r=0
##if data_hoje != feriados & dia_semana!='6' or '7':
def iterdates(date1, date2):
    one_day = datetime.timedelta(days = 1)
    current = date1
    while current <=date2:
        yield current
        current += one_day

date5 = datetime.datetime.strptime(i, '%d/%m/%Y').date()
date6 = datetime.datetime.strptime(a, '%d/%m/%Y').date()
y=0
for d in iterdates(date5, date6):
    if d.weekday() not in (5, 6):
      y=y+1

#####################################################
for ll in feriados_atual[date5:date6] :
    if feriado.weekday()==(6 or 5):
      r=r
    else: r=r+1
    

Dias_uteis_hoje =y-r
Dias_uteis_hoje

"""#Buscando Status de Controle de COntas

##Tratar o dados extraídos da revisão de propostas
"""

df=pd.read_excel(f"{caminho}/{arquivo1}")
tempo =df.query('Status=="DONE"')
averb=pd.read_excel(f"{caminho}/{arquivo1}",dtype={'CNPJ':str})
angel=df.drop([ 'Nº de parcelas'], inplace=False, axis=1)
analise_date=pd.read_excel(f"{caminho}/{arquivo1}")

Analise_Refin=df.query('Status!="DONE"')

verzi_prop=df[['NomeNegocio',	'Nome'	,'CPF'	,'Valor Total'	,'Status',	'Data da Solicitação',	'Data de Pagamento',	'Taxa (%)',	'Nº de parcelas',	'CNPJ','Grupo']]

cokipit_abertos=df[['NomeNegocio',	'Nome'	,'CPF'	,'Valor Total'	,'Status',	'Data da Solicitação',	'Data de Pagamento',	'Taxa (%)',	'Nº de parcelas',	'CNPJ','Grupo']]

range_minmax=df[['NomeNegocio',	'Nome'	,'CPF'	,'Valor Total'	,'Status',	'Data da Solicitação',	'Data de Pagamento',	'Taxa (%)',	'Nº de parcelas',	'CNPJ','Grupo','Fundo']]

df.drop(['Fundo','CPF',
         'Salário Líquido', 'Margem Consignável','Data do aceite da CCB','Dispensar Averbação',
         'Última Atualização', 'Dias desde a última Atualização','Origem',
         'CCB', 'Valor solicitado', 'Taxa (%)', 'Nº de parcelas', 'Valor da parcela' ], inplace=True, axis=1)

pea=pd.DataFrame(df)
df=df.groupby(['Grupo']).agg({'Valor Total':'sum'}).reset_index()

df['Valor Total']=df['Valor Total'].round(2)



"""#Buscar Controle de contas"""

tu= gc.open_by_url('https://docs.google.com/spreadsheets/d/1Jkj-WQIc47rg2_SGhANIOsivUVRn1Jy6VhdeRRNgcQA/edit#gid=1691787312')
meta= tu.worksheet('Projeção Mensal (rev Q4)')
dados = meta.get_all_records()
meta = pd.DataFrame(dados)

meta_sass=tu.worksheet('Meta Empresa x Time (Q3)')
dados_sass=meta_sass.get_all_values()
meta_sass=pd.DataFrame(dados_sass)

meta_sass=meta_sass[[0,1,2,3,4,5,6,7,8,9,10,11,12]]

meta_sass.columns=meta_sass.iloc[0]

Meses={1:'Janeiro', 2:'Fevereiro', 3:'Março', 4:'Abril', 5:'Maio', 6:'Junho', 7:'Julho',8:'Agosto', 9:'Setembro', 10:'Outubro', 11:'Novembro', 12:'Dezembro'}
data_mes=Meses.get(mes)
data_mes

meta_sass=meta_sass.rename(columns={"":"Modelos"})

meta_sass=meta_sass[[data_mes,"Modelos"]]

meta_sass[data_mes]=meta_sass[data_mes].str.slice(2,)
meta_sass[data_mes]=meta_sass[data_mes].str.replace('.','')
meta_sass[data_mes]=meta_sass[data_mes].str.replace(',','.')

for i in meta_sass.index:
  if meta_sass["Modelos"][i]=="SaaS":
    u=meta_sass[data_mes][i]

u=float(u)

u=round(u)

Meta_anual=meta.loc[:,['Grupo','Modelo de Negócio', 'Classificação','Status', data_mes]]

Meta_anual=Meta_anual.rename(columns={data_mes:'Meta Produção 2022'})

Meta_anual['Meta Produção 2022']=Meta_anual['Meta Produção 2022'].str.slice(2,)
Meta_anual['Meta Produção 2022']=Meta_anual['Meta Produção 2022'].str.replace('.','')
Meta_anual['Meta Produção 2022']=Meta_anual['Meta Produção 2022'].str.replace(',','.')

"""##Tratando metas anuais"""

Meta_anual['Meta Produção 2022']=pd.to_numeric(Meta_anual['Meta Produção 2022'])

Meta_anual['Meta Produção 2022'].sum()

pro=Meta_anual.groupby(['Grupo', 'Modelo de Negócio', 'Classificação', 'Status']).agg({'Meta Produção 2022':'sum'}).reset_index()
# pro=pro.drop(pro.index[[0]])

pro['Grupo']=pro['Grupo'].str.upper()
pro=pro.rename(columns={'Meta Produção 2022':'Meta de Produção Mensal'})
df['Grupo']=df['Grupo'].str.upper()

Analise_diaria = pd.merge(df, pro,how = 'outer')

Analise_diaria['Valor Total']=Analise_diaria['Valor Total'].fillna(0)
Analise_diaria['Meta de Produção Mensal']=Analise_diaria['Meta de Produção Mensal'].fillna(0)
Analise_diaria=Analise_diaria.fillna('')

Analise_diaria.drop(['Valor Total'], axis=1, inplace=True)

Analise_diaria['Modelo de Negócio']=Analise_diaria['Modelo de Negócio'].replace("", "SaaS", regex=True)

"""#Buscado valores em Aberto

##Status Tratados

###Status em ánalise
"""

pea1=pea.loc[:, ['Grupo', 'Data da Solicitação', 'Valor Total', 'Status', 'Data de Pagamento']]

def where(g):##def para selecionar somente status em anilise
  if g=='DONE' :
    g=0
  elif g=='PAID':
      g=0
  elif g=='REJECTED_PAKETA':
        g=0
  elif g=='REJECTED_RH':
           g=0
  elif g=='CANCELED':
           g=0
  else:g=1 
  return g
pea1['Propostas_em_aberto']=pea1['Status'].apply(where)
pea1['Grupo']=pea1['Grupo'].str.upper()

pea1['Propostas em aberto valor']=pea1.loc[(pea1['Propostas_em_aberto']!=0),['Valor Total']]

why=pea1.loc[:, ['Grupo','Propostas_em_aberto' ]]
why= why.groupby([ 'Grupo']).agg({'Propostas_em_aberto':'sum'}).reset_index()
why['Grupo']=why['Grupo'].str.upper()

Analise_diaria = pd.merge(Analise_diaria, why,how = 'left', on = 'Grupo')

pea1['Data da Solicitação']=pea1['Data da Solicitação'].str.slice(3,10)
pea1['Data de Pagamento']=pea1['Data de Pagamento'].str.slice(3,10)

pea1=pea1.query("`Data da Solicitação`==@data_atual | `Data de Pagamento`==@data_atual")

##Se eu solicitei esse mês passado e foi pago esse mês, significa que o valor deve ser do mês passado. Precisa-se corrigir isso em outra planilha
def pagos(x):
  if x =='DONE':
    x=1
  else: x=0
  return x
pea1['Status Pagos']=pea1['Status'].apply(pagos)
pea1['Produção Total']=pea1.loc[(pea1["Status Pagos"]==1), ['Valor Total']]
pea1['Produção Mês Atual']=pea1.loc[(pea1["Data de Pagamento"]==data_atual), ['Produção Total']]

pea1['Prop_tds']=pea1['Status'].apply(lambda x: 1)

pea1['Propostas Geradas']=pea1.loc[(pea1['Data de Pagamento']==data_atual), ['Status Pagos']]

proto=pea1.groupby([ 'Grupo']).agg({'Produção Mês Atual':'sum'}).reset_index()

Propostas_geradas=pea1.loc[:, ['Grupo', 'Propostas Geradas', 'Prop_tds']]

"""##Valores em aberto"""

Analise_diaria = pd.merge(Analise_diaria, proto,how = 'left', on = 'Grupo')

def vira(x):
  x=1
  return x
pea1['Solicitações']= pea1['Status'].apply(vira)

pea1['Solicitações Mês Atual']=pea1.loc[(pea1["Data da Solicitação"]==data_atual), ['Propostas em aberto valor']]
pea1['Solicitações Mês Atual']=pea1['Solicitações Mês Atual'].fillna('0')
pea1['Solicitações Mês Atual']=pd.Series(pea1['Solicitações Mês Atual'], dtype="float")

xvy=pea1.groupby([ 'Grupo']).agg({'Solicitações Mês Atual':'sum'}).reset_index()

xvy['Solicitações Mês Atual'].sum()

Analise_diaria = pd.merge(Analise_diaria, xvy,how = 'left', on = 'Grupo')

"""#Calculando Dias úteis do mês atual e quantos dias tem o mês

##Analise diaria da Meta e da Produção
"""

##Proporção de dias uteis na data de hoje, com os dias uteis do mês

Analise_diaria=Analise_diaria.rename(columns={'Solicitações Mês Atual': 'Propostas em aberto'})
Analise_diaria=Analise_diaria.fillna('')

Analise_diaria.drop(Analise_diaria.loc[Analise_diaria['Grupo']==''].index, inplace=True)

"""#Fazendo Cockpit semanal"""

def generate_labelencoder(atts):
  for attr in atts:
    cockpit[attr]=pd.to_numeric(cockpit[attr])
    cockpit[attr]=cockpit[attr].fillna(0)
    return cockpit

cockpit=pd.DataFrame(Analise_diaria)
cockpit = generate_labelencoder(['Propostas em aberto', 'Meta de Produção Mensal', 'Produção Mês Atual'])
cockpit = generate_labelencoder(['Produção Mês Atual'])
tudo=cockpit

cockpit=cockpit.groupby(['Modelo de Negócio']).agg({'Produção Mês Atual':'sum','Propostas em aberto':'sum', 'Meta de Produção Mensal':'sum' }).reset_index()

cockpit['Produção R$']=cockpit['Produção Mês Atual']
cockpit['Produção x Meta']=cockpit['Produção R$']/cockpit['Meta de Produção Mensal']

Cockpit_mensal=cockpit.drop(['Produção Mês Atual', 'Propostas em aberto'], inplace=False, axis=1)
Cockpit_mensal=Cockpit_mensal.replace([np.inf], np.nan)
Cockpit_mensal['Produção x Meta']=Cockpit_mensal['Produção x Meta']*100
Cockpit_mensal=Cockpit_mensal.fillna(0)

Cockpit_mensal

"""#Cobertura Histórica

"""

import re 
cob=pea

cob=cob.loc[:,['Grupo', 'Valor Total', 'Status', 'Data de Pagamento', 'Data da Solicitação', 'Modelo de negócio']]

semana=datetime.datetime.now(IST)
semana_hoje=semana.strftime('%d/%m/%Y')
dia0= str("01")
semana_inicio=dia0+'/'+"0"+str(mes)+'/'+str(ano)
semana_inicio=str(semana_inicio)
semana_fim=fim_mes

cob['Status_sol']=cob['Status'].apply(where)

cob['Data de Pagamento']=pd.Series(cob['Data de Pagamento'], dtype="string")
cob['Data da Solicitação']=pd.Series(cob['Data da Solicitação'], dtype="string")

cob['Mes_de_pagamento']=cob['Data de Pagamento'].str.slice(3,)
cob['Mes_de_solicitação']=cob['Data da Solicitação'].str.slice(3,)

"""###Tratar semanas em python"""

produzido=cob

comp=int(1)

prod=cob.query('Status_sol==1')

cob=prod.query('Mes_de_solicitação==@data_atual')

cob['Valor Total'].sum()

def whiles(lar):
  if lar=='DONE':
    lar=1
  else:lar=0
  return lar
produzido['Status_pag']=produzido['Status'].apply(whiles)

produzido=produzido.query('Status_pag==1')

produzido=produzido.query('Mes_de_pagamento==@data_atual')

produzido=produzido.loc[:,['Grupo', 'Valor Total',  'Data de Pagamento']]

produzido['dia_pag']=produzido['Data de Pagamento'].str.slice(0,2)

produzido['dia_pag']=pd.to_numeric(produzido['dia_pag'])

produzido['Data_pag']=produzido['Data de Pagamento'].apply(lambda x: re.sub("/","",x))
produzido['Data_pag']=produzido['Data_pag'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date())

produzido['Data_pag']=pd.to_datetime(produzido['Data_pag'])

produzido['Semana']=produzido['Data_pag'].dt.to_period('W-SUN')

produzido['Semana2']=produzido['Data_pag'].apply(lambda x: datetime.datetime.strftime(x, "%U"))

"""##SEMANAS EM PYTHON"""

def semana(x):
  if 1<=x<=7:
    x="semana1"
  elif 7<x<=14:
    x="semana2"
  elif 14<x<=21:
    x="semana3"
  elif x>21:
    x="semana4"
  return x
produzido['conta']=produzido['dia_pag'].apply(semana)

produzido=produzido.groupby(['Grupo', 'conta']).agg({'Valor Total':'sum'}).reset_index()

cob['dia_sol']= cob['Data da Solicitação'].str.slice(0,2)

cob['dia_sol']=pd.to_numeric(cob['dia_sol'])

cob['dia_sol']=cob['dia_sol'].apply(semana)

cob=cob.loc[:,['Grupo', 'Valor Total', 'dia_sol']]

cob=cob.fillna(0)

produzido['Valor Total'].sum()

cob=cob.rename(columns={'dia_sol':'conta'})

cob=cob.reindex(columns=['Grupo', 'conta', 'Valor Total'])

cob_hist=produzido

cobertura=cob_hist.groupby(['Grupo', 'conta']).agg({'Valor Total':'sum'}).reset_index()

Produção=pd.DataFrame(cobertura)

Produção['Produção semana 1']=Produção.loc[(Produção['conta']=='semana1'), ['Valor Total']]
Produção['Produção semana 2']=Produção.loc[(Produção['conta']=='semana2'), ['Valor Total']]
Produção['Produção semana 3']=Produção.loc[(Produção['conta']=='semana3'), ['Valor Total']]
Produção['Produção semana 4']=Produção.loc[(Produção['conta']=='semana4'), ['Valor Total']]

Produção=Produção.fillna(0)

cob_hist=tudo.loc[:, ['Grupo', 'Modelo de Negócio']]

var=cob_hist

"""#Pivot"""

cobertura['Grupo']=cobertura['Grupo'].str.upper()
cob_hist = pd.merge(cob_hist, cobertura,how = 'outer')

Produção['Grupo']=Produção['Grupo'].str.upper()
Analise_diaria = pd.merge(Produção, Analise_diaria,how = 'outer')

Analise_diaria.drop(['conta', 'Valor Total'], inplace=True, axis=1)

Analise_diaria=Analise_diaria.fillna(0)

"""###Agrupando planilha de controle diário"""

Analise_diaria=Analise_diaria.groupby(['Grupo', 'Modelo de Negócio', 'Classificação', 'Status', 'Meta de Produção Mensal','Produção Mês Atual','Propostas em aberto']).agg({
     'Produção semana 1':'sum','Produção semana 2':'sum', 'Produção semana 3':'sum', 'Produção semana 4':'sum'}).reset_index()

"""#Campanhas análise"""

#Grupo	Campanha Responsável	Data Status	Público	Solicitações Geradas	Propostas Geradas	Propostas PAGAS	Conversão	Comentários	
#MQL a pessoa que iniciou a simulação
# SQl a pessoa que concluiu a simulação, tem tudo para contratar
# Proposta paga contratou
cia= gc.open_by_url('https://docs.google.com/spreadsheets/d/1mac-R_wD8Di3LNAgI8c5-juwW8udkbowx1WkoVaMbEI/edit#gid=1901129715')
tabelão=cia.worksheet('Tabelão')
tabelão=tabelão.get_all_records()
campanha=pd.DataFrame(tabelão)

campanha=campanha.query('Ano==@ano & Mês==@mes')

campanha

def generate(atts):
  for attr in atts:
    campanha[attr]=pd.to_numeric(campanha[attr])
    campanha[attr]=campanha[attr].fillna(0)
    return campanha
campanha['SQL']=pd.to_numeric(campanha['SQL'])
campanha['MQL']=pd.to_numeric(campanha['MQL'])
campanha['Proposta Paga']=pd.to_numeric(campanha['Proposta Paga'])
campanha['Proposta Paga (R$)']=campanha['Proposta Paga (R$)'].str.replace('.', '')
campanha['Proposta Paga (R$)']=campanha['Proposta Paga (R$)'].replace(',', '.', regex=True)
campanha['Proposta Paga (R$)']=pd.to_numeric(campanha['Proposta Paga (R$)'])

print

campanha['Custo']=campanha['Custo'].str.replace('.', '')
campanha['Custo']=campanha['Custo'].replace(',', '.', regex=True)

campanha['Custo']=campanha['Custo'].replace('R', '', regex=True)
campanha['Custo']=campanha['Custo'].replace('[#,@,$]', '', regex=True)

campanha['Custo']=pd.to_numeric(campanha['Custo'])

campanha=campanha.fillna(0)

campanha['Empresa']=campanha['Empresa'].str.upper()
campanha.drop(campanha.loc[campanha['Empresa']==''].index, inplace=True)

campanha=campanha.round(1)

campanha['Produto']= campanha['Produto'].str.replace('E2E', 'End to End')

campanha['Campanha']=pd.Series(campanha['Campanha'], dtype="string")

campanha=campanha.rename(columns={'Empresa':'Grupo'})

campanha.drop(['Descrição','Mês', 'Semana', 'Ano', 'Valor solicitado', 'Alcance', 'Custo' ], inplace=True, axis=1)

def aplica(f):
  if f=='':
    f="Nenhuma" 
  return f
campanha['Campanha']=campanha['Campanha'].apply(aplica)

Analise_diaria['Status']=Analise_diaria.apply(lambda x: "ATIVO" if x.Status=="" else x.Status , axis =1)

Analise_diaria.drop(Analise_diaria.loc[Analise_diaria['Grupo']=='TESTES PAKETÁ'].index, inplace=True)

"""#Reprovações/Cs OPS

###Reprovações dos 3 ultimos meses
"""

reprov=pd.read_excel(f"{caminho5}/{arquivo5}")
reprov3=pd.read_excel(f"{caminho5}/{arquivo5}")

aps= gc.open_by_url('https://docs.google.com/spreadsheets/d/1bFeLNz-SbWdUQKGu1LApxF0yueYV3tQMJFa2TQti_YY/edit#gid=2039134612')
aspd= aps.worksheet('Tradução do motivo de reprovação')
giro =aspd.get_all_records()
tdm= pd.DataFrame(giro)

tdm=tdm.rename(columns={'Tradução que aparece no cockpit':'Traduzido','Motivo no banco de dados':'Motivo Reprovação' })

reprov=reprov.loc[:,['Motivo Reprovação','Grupo', 'Data/Horário Reprovação','Status', 'Comentário Reprovação','CPF Normalizado','Valor Total', 'CNPJ','Tomador','CPF Tomador',]]

reprov['Quantidade Reprovada']=reprov['CPF Normalizado'].apply(lambda x:1 if x!="NaN" else x)

reprov['Comentário Reprovação']=reprov['Comentário Reprovação'].fillna('')

reprov['Comentário Reprovação']=reprov['Comentário Reprovação'].apply( lambda x: "Sem comentário" if x=='' else x)

reprov['Data/Horário Reprovação']=pd.to_datetime(reprov['Data/Horário Reprovação'])

reprov['Data']= pd.to_datetime(reprov['Data/Horário Reprovação']).dt.date

reprov['Data']=pd.to_datetime(reprov['Data'])

reprov['Mes']=reprov['Data'].dt.month
reprov['Ano']=reprov['Data'].dt.year

mes1=mes-1
mes2=mes1-1
mes3=mes2-1
mes_passado=Meses.get(mes1)
mes_retrasado=Meses.get(mes2)
mes_retrasado2=Meses.get(mes3)

reprov[mes_passado]=reprov.loc[(reprov['Mes']==mes1),['Quantidade Reprovada']]
reprov[mes_retrasado]=reprov.loc[(reprov['Mes']==mes2),['Quantidade Reprovada']]
reprov[mes_retrasado2]=reprov.loc[(reprov['Mes']==mes3),['Quantidade Reprovada']]
reprov[data_mes]=reprov.loc[(reprov['Mes']==mes),['Quantidade Reprovada']]

reprov=reprov.query('Mes==@mes | Mes==@mes1 | Mes==@mes2 | Mes==@mes3')

reprov=reprov.query('Ano==@ano')

reprov['Motivo Reprovação']=reprov['Motivo Reprovação'].fillna('MOTIVO NÃO IDENTIFICADO')
reprov=reprov.fillna(0)

Reprovação=reprov.groupby(['Grupo', 'Motivo Reprovação', 'Status', 'Comentário Reprovação','Tomador', 'CPF Tomador']).agg({data_mes:'sum', mes_passado:'sum', mes_retrasado:'sum', mes_retrasado2:'sum' }).reset_index()

Reprovação['Grupo']=Reprovação['Grupo'].str.upper()

ap=Analise_diaria.loc[:,['Grupo', 'Modelo de Negócio']]

Reprovação=pd.merge(Reprovação, ap, how='left', on='Grupo' )

Reprovação=Reprovação.groupby(['Grupo', 'Motivo Reprovação', 'Status', 'Comentário Reprovação', 'Modelo de Negócio','Tomador', 'CPF Tomador']).agg({data_mes:'sum', mes_passado:'sum', mes_retrasado:'sum', mes_retrasado2:'sum' }).reset_index()

Reprovação=pd.merge(Reprovação, tdm, how='left', on='Motivo Reprovação')

Reprovação['Traduzido']=Reprovação['Traduzido'].fillna('')

Reprovação['Traduzido']=Reprovação['Traduzido'].apply(lambda x: 'MOTIVO NÃO IDENTIFICADO' if x=='' else x)

Reprovação= Reprovação[['Grupo', 'Traduzido', 'Status', 'Comentário Reprovação', 'Modelo de Negócio', 'Tomador', 'CPF Tomador', data_mes,mes_passado,mes_retrasado,mes_retrasado2]]

Reprovação['Setembro'].sum()

"""#CS SALES

##Buscar arquivo com todas as empresas cadastradas na base
"""

emp=pd.read_excel((f"{caminho2}/{arquivo2}"))
empx=pd.read_excel((f"{caminho2}/{arquivo2}"),dtype={'cnpj':str})
minha_coluna=pd.read_excel((f"{caminho2}/{arquivo2}"),dtype={'cnpj': str})
funcionarios=pd.read_csv((f"{caminho3}/{arquivo3}"))
funcionarios_contrat=pd.read_csv((f"{caminho3}/{arquivo3}"),dtype={'CNPJ': str,'CPF': str})
funcionarios_total=pd.read_csv((f"{caminho3}/{arquivo3}"),dtype={'CNPJ': str,'CPF': str})
fgts_julio=funcionarios[['CPF','Telefone','Nome','Salário Bruto','Empresa']]
funcionarios=funcionarios[['Empresa','Perfil','Nome','CPF','Grupo','CNPJ','Margem Consignável','Telefone','E-mail']]
elegiveis=funcionarios
funcionarios_cancelados=funcionarios[['CPF', 'Telefone','E-mail']]
func_cpf=funcionarios[['Empresa','Perfil','Nome','CPF','Grupo','CNPJ','Margem Consignável','Telefone','E-mail']]

funcionarios_total['Grupo']=funcionarios_total['Grupo'].str.upper()

funcionarios_total[['Dia da semana','Mês','Dia','Hora','Fuso','Ano']]=funcionarios_total['Data de Admissão'].str.split(' ', expand=True)

funcionarios_total['Data']=funcionarios_total['Dia']+'/'+funcionarios_total['Mês']+'/'+funcionarios_total['Ano']

funcionarios_total['Data']=pd.to_datetime(funcionarios_total['Data'],format="%d/%b/%Y", errors='coerce').apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else '')

empx=empx[['paketa_groups → name','agreementDate','createdAt','updatedAt','tradeName']]

re_x=funcionarios_cancelados[['CPF','Telefone','E-mail']]
re_x=re_x.rename(columns={'CPF':'CPF Tomador'})

re_p=range_minmax[['CPF','Valor Total','Status']]

re_p=re_p.query('Status=="REJECTED_PAKETA" | Status=="REJECTED_RH"')

re_p=range_minmax[['CPF','Valor Total']]

re_p=re_p.rename(columns={'CPF':'CPF Tomador'})

Reprovação=pd.merge(Reprovação,re_x,how='left', on='CPF Tomador')

Reprovação=pd.merge(Reprovação,re_p,how='left', on='CPF Tomador')

Reprovação=Reprovação.fillna('')

Reprovação=Reprovação.drop_duplicates(subset=['CPF Tomador','Traduzido',data_mes,mes_passado,mes_retrasado,mes_retrasado2])

"""###CNPJ CSOPS"""

maria=elegiveis.loc[:,['Empresa', 'Grupo','CNPJ','Nome','CPF','Telefone']]

minha_coluna=minha_coluna.loc[:,['cnpj', 'tradeName','paketa_groups → name']]

minha_coluna=minha_coluna.rename(columns={'paketa_groups → name':'GRUPO','cnpj':'CNPJ','company':'Razão Social',})

minha_coluna['GRUPO']=minha_coluna['GRUPO'].str.upper()

minha_coluna=minha_coluna.fillna('')

minha_coluna=minha_coluna[['GRUPO','CNPJ','tradeName']]

minha_coluna['CNPJ NÙMERO']=pd.to_numeric(minha_coluna['CNPJ'])

"""###CNPJ CS SALES"""

func_simu=elegiveis.loc[:,['Empresa','Grupo','CPF']]

emp=emp.loc[:,['cnpj', 'company','customfields_modelodenegocio','status', 'address_city', 'address_address', 'address_number','customfields_tipodeempresa','paketa_groups → name']]

emp=emp.rename(columns={'cnpj':'Empresa','company':'Razão Social','customfields_modelodenegocio':'Modelo de negócio', 'address_city':'Filial', 'address_address':'Endereço', 'customfields_tipodeempresa':'Tipo','paketa_groups → name':'GRUPO'})

emp['Endereço']=emp['Endereço']+","+emp['address_number']

emp.drop(['address_number'], inplace=True, axis=1)

funcionarios['CPF']=funcionarios.apply(lambda x:1 if x.CPF !="NUMERO"  else x.status, axis=1 )

funcionarios['Empresa']=funcionarios['Empresa'].astype(str)

funcionarios=funcionarios.groupby(['CNPJ']).agg({'CPF':'sum'}).reset_index()
funcionarios=funcionarios.rename(columns={'CNPJ':'Empresa'})

"""##GRUPOS E FILIAIS"""

Grupos_filiais=pd.merge(funcionarios, emp, how='left', on='Empresa')

Grupos_filiais['CPF']=Grupos_filiais['CPF'].fillna('')
Grupos_filiais=Grupos_filiais.fillna('')

Grupos_filiais=Grupos_filiais.groupby(['Empresa', 'Razão Social', 'Modelo de negócio', 'status', 'Filial', 'Endereço', 'Tipo','GRUPO']).sum().reset_index()

Grupos_filiais=Grupos_filiais.rename(columns={'CPF':'Headcount'})

Grupos_filiais['status']=Grupos_filiais.apply(lambda x: "ATIVO" if x.status=="ENABLED" else x.status , axis =1)

"""##Produção por cnpj"""

sales=pea.query('Status=="DONE"')
sales=sales.rename(columns={'CNPJ':'Empresa'})

"""##Medias de produção por datas"""

mes_anterior1= data_hoje-relativedelta(months=1)
mes_anterior2=mes_anterior1-relativedelta(months=1)
mes_anterior3=mes_anterior2-relativedelta(months=1)
mes_anterior1=mes_anterior1.strftime('%m/%Y')
mes_anterior2=mes_anterior2.strftime('%m/%Y')
mes_anterior3=mes_anterior3.strftime('%m/%Y')

sales['Status']=sales.apply(lambda x: 1 if x.Status=="DONE" else x.status , axis =1)

sales['Valort']=sales['Status']
sales['Valorm']=sales['Status']

media_mes=sales.groupby(['Empresa']).agg({'Valor Total':'mean', 'Valort':'sum'}).reset_index()

sales['Data de Pagamento']=sales['Data de Pagamento'].str.slice(3,)

media_3meses=sales.query('`Data de Pagamento`==@mes_anterior1 |`Data de Pagamento`==@mes_anterior2 | `Data de Pagamento`==@mes_anterior3')

media_3meses=media_3meses.groupby(['Empresa']).agg({'Valor Total':'mean', 'Valorm':'sum'}).reset_index()

"""##Concatenando com Grupos e Filiais"""

GF=pd.merge(Grupos_filiais, media_mes, how = 'outer')

GF=GF.rename(columns={'Valor Total':'Media Mensal', 'Valort':'Propostas Total'})
GF=pd.merge(GF,media_3meses, how='outer' )
GF=GF.rename(columns={'Valor Total':'Media Mensal de produção 3 meses', 'Valorm':'Propostas 3 meses'})
GF['Headcount']=GF['Headcount'].fillna(0)
GF['Media Mensal']=GF['Media Mensal'].fillna(0)
GF['Propostas Total']=GF['Propostas Total'].fillna(0)
GF['Propostas 3 meses']=GF['Propostas 3 meses'].fillna(0)
GF['Media Mensal de produção 3 meses']=GF['Media Mensal de produção 3 meses'].fillna(0)
GF=GF.fillna('')

gf_sales=GF.groupby(['Empresa', 'Razão Social', 'Modelo de negócio', 'Filial', 'status','Endereço', 'Tipo','GRUPO']).agg({'Headcount':'sum', 'Media Mensal':'sum', 'Media Mensal de produção 3 meses':'sum', 'Propostas Total':'sum', 'Propostas 3 meses':'sum'}).reset_index()

gf_sales=gf_sales.round(2)

gf_sales=gf_sales.query('status=="ATIVO" | status==""')

spring=gc.open_by_url('https://docs.google.com/spreadsheets/d/1OYa9v0yu5qiDMcnu1iv1zgixLqtG5xWVbvG0O6EyN6g/edit#gid=505924010')
gp=spring.worksheet('Grupos e Filiais')
gp.update([gf_sales.columns.values.tolist()] + gf_sales.values.tolist())

"""#SIMULAÇÕES"""

SIMULAÇÕES=pd.read_csv((f"{caminho4}/{arquivo4}"))
SIMULAÇÕES_CPF=pd.read_csv((f"{caminho4}/{arquivo4}"),dtype={'CPF': str,'Celular':str})

"""#CS SALES, PRODUÇÃO POR EMPRESA

###Tratando Datas
"""

funcionarios=funcionarios.rename(columns={'Empresa':'CNPJ'})

normal=pd.DataFrame(pea)
import re

normal['Valor Total']=normal['Valor Total'].fillna(0)
normal=normal.fillna('')

normal['Data Solicitação']=normal['Data da Solicitação'].apply(lambda x: re.sub("/","",x))

normal['Data Pagamento']=normal['Data de Pagamento'].apply(lambda x: re.sub("/","",x))

normal['Data Solicitação']=normal['Data Solicitação'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date())

normal['Data Pagamento']=normal['Data Pagamento'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date() if x!='' else x)

normal['Data Solicitação']=pd.to_datetime(normal['Data Solicitação'])

normal['Data Pagamento']=pd.to_datetime(normal['Data Pagamento'])

normal=normal.query('`Data Solicitação`>="2022-04-01"| `Data Pagamento`>="2022-04-01"')

normal.drop(['Nome', 'CPF NORMALIZADO', 'Data da Solicitação', 'Data de Pagamento'], axis=1, inplace=True)

normal['Data Pagamento'] = normal['Data Pagamento'].astype(object).where(normal['Data Pagamento'].notnull(),np.nan)

normal=normal.fillna('')

normal['Data Pagamento']=pd.Series(normal['Data Pagamento'], dtype=("string"))

normal['Data Pagamento']=normal['Data Pagamento'].str.slice(0,10)

normal['Data Solicitação']=pd.Series(normal['Data Solicitação'], dtype=("string"))

normal=normal.loc[:,['CNPJ', 'NomeNegocio', 'Grupo', 'Valor Total', 'Status', 'Modelo de negócio', 'Data Solicitação', 'Data Pagamento']]

normal['Propostas Pagas']=normal.loc[(normal['Status']=="DONE"),['Valor Total']]

normal['Propostas Pagas']=normal['Propostas Pagas'].fillna(0)
normal['Propostas Pagas']=normal['Propostas Pagas'].apply(lambda x: 1 if x!=0 else x)

normal['Propostas Solicitadas']=normal['Status'].apply(lambda x: 1 if x!=0 else x)

"""##Mes e dia de solicitação e propostas pagas"""

normal['Mes da Solicitação']=normal['Data Solicitação'].str.slice(5,7)
normal['Dia da Solicitação']=normal['Data Solicitação'].str.slice(8,)

normal['Mes do Pagamento']=normal['Data Pagamento'].apply(lambda x: x[5:7] if x!="" else x)

normal['Dia do Pagamento']=normal['Data Pagamento'].apply(lambda x: x[8:] if x!="" else x)

normal['Mes do Pagamento']= pd.to_numeric(normal['Mes do Pagamento'])

normal['Mes da Solicitação']=pd.Series(normal['Mes da Solicitação'], dtype="int64")

"""##Criando quantidade de propostas pagas em Analise diaria"""

product=normal.query('`Mes da Solicitação`==@mes | `Mes do Pagamento`==@mes')

product

product['Propostas_pagas']=product.loc[(product['Mes do Pagamento']==mes),['Propostas Pagas']]
product['Propostas Solicitadas']=product.loc[(product['Mes da Solicitação']==mes),['Propostas Solicitadas']]

product

product=product.groupby(['Grupo']).agg({'Propostas_pagas':'sum', 'Propostas Solicitadas':'sum'}).reset_index()

product['Grupo']=product['Grupo'].str.upper()

product['Propostas_pagas'].sum()

product=product.rename(columns={'Propostas_pagas': 'Quantidade de Propostas Pagas', 'Propostas Solicitadas':'Quantidade de Propostas Solicitadas'})

Analise_diaria=pd.merge(Analise_diaria, product, how = 'left', on = 'Grupo')

Analise_diaria['Quantidade de Propostas Solicitadas'].sum()

Analise_diaria['Quantidade de Propostas Solicitadas']=Analise_diaria['Quantidade de Propostas Solicitadas'].fillna(0)

Analise_diaria['Quantidade de Propostas Pagas']=Analise_diaria['Quantidade de Propostas Pagas'].fillna(0)

Analise_diaria=pd.merge(Analise_diaria, why, how = 'left', on = 'Grupo' )

Analise_diaria['Propostas_em_aberto']=Analise_diaria['Propostas_em_aberto'].fillna(0)

normal=normal[['CNPJ','NomeNegocio', 'Grupo','Valor Total', 'Status', 'Modelo de negócio', 'Data Solicitação','Mes da Solicitação', 'Dia da Solicitação', 'Data Pagamento', 'Mes do Pagamento', 'Dia do Pagamento', 'Propostas Pagas', 'Propostas Solicitadas']]

normal['Mes do Pagamento']=normal['Mes do Pagamento'].fillna('')

normal['Dia do Pagamento']=pd.to_numeric(normal['Dia do Pagamento'])

normal['Dia do Pagamento']=normal['Dia do Pagamento'].fillna(0)

"""###Simulações por mês"""

empresa=SIMULAÇÕES.loc[:,['Grupo', 'CPF', 'Data', 'CNPJ']]

empresa['CPF']=empresa['CPF'].apply(lambda x: 1 if x!=a else x)

empresa['Data']=empresa['Data'].apply(str)
empresa['Data']=empresa['Data'].apply(lambda x: re.sub("/","",x))

empresa=empresa.query('Data!="nan"')

empresa['Data']=empresa['Data'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date())

empresa['Data']=pd.to_datetime(empresa['Data'])

empresa['Data_mes']=empresa['Data'].dt.month
empresa['ano_mes']=empresa['Data'].dt.year
empresa['Dia_mes']=empresa['Data'].apply(lambda x: x.day)

empresa=empresa.query('Data_mes>=4 & ano_mes==@ano')

empresa=empresa.loc[:,['Grupo', 'Data', 'CPF','CNPJ', 'Data_mes', 'Dia_mes']]
empresa=empresa.rename(columns={'CPF':'Simulações'})

empresa=empresa.groupby(['CNPJ', 'Grupo', 'Data','Data_mes', 'Dia_mes']).sum().reset_index()

empresa['Data']=pd.Series(empresa['Data'], dtype="string")

"""###Funcionarios por CNPJ, EMPRESA, GRUPO"""

func_empresa=elegiveis.groupby(['Empresa', 'Grupo', 'CNPJ']).agg({'CPF':'sum'}).reset_index()

func_empresa['Grupo']=func_empresa['Grupo'].str.upper()

"""###Mandar para Cs Sales

"""

valor=spring.worksheet('Produção por empresa')
valor.update([normal.columns.values.tolist()] + normal.values.tolist())

sol=spring.worksheet('Simulações por empresa')
sol.update([empresa.columns.values.tolist()]+ empresa.values.tolist())

funcemp=spring.worksheet('Funcionarios por empresa')
cell_list = funcemp.range("A1:O5000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
funcemp.update_cells(cell_list)
funcemp.update([func_empresa.columns.values.tolist()]+func_empresa.values.tolist())

"""
#Mandar para planilha cs ops"""

empresas_sem_grupo=minha_coluna.query('GRUPO==""')

Dp= gc.open_by_url('https://docs.google.com/spreadsheets/d/1bFeLNz-SbWdUQKGu1LApxF0yueYV3tQMJFa2TQti_YY/edit#gid=168572371')
sheet2=Dp.worksheet('Análise das Contas (DIÁRIO)')
emp_csm=Dp.worksheet('EMPRESAS POR GRUPO E CSM')
cell_list = emp_csm.range("A1:D8000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
emp_csm.update_cells(cell_list)
emp_csm.update([minha_coluna.columns.values.tolist()]+ minha_coluna.values.tolist())
emp_sem_gp=Dp.worksheet('Empresas sem informação')
emp_sem_gp.clear()
emp_sem_gp.update([empresas_sem_grupo.columns.values.tolist()]+ empresas_sem_grupo.values.tolist())
sheet3=Dp.worksheet('Planilha controle campanhas')
REPROV=Dp.worksheet('MOTIVOS/REPROVAÇÕES/MÊS')
cell_list = REPROV.range("A1:k8000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
REPROV.update_cells(cell_list)
REPROV.update([Reprovação.columns.values.tolist()]+ Reprovação.values.tolist())
# sheet3.update([campanha.columns.values.tolist()]+ campanha.values.tolist())
cock=Dp.worksheet('COCKPIT MENSAL')
cock.update('a33',u)
# cockup=([Cockpit_mensal.columns.values.tolist()]+Cockpit_mensal.values.tolist())
#sheet3.update([cob_hist.columns.values.tolist()]+cob_hist.values.tolist())

# E2E_clas=([E2E.columns.values.tolist()]+E2E.values.tolist())
# cock_mensal= cock.range('B29:D32')
# E2E_plas=cock.range('F30:H33')
# arrayE2E=np.array(E2E_clas)
# array = np.array(cockup)

# for cells in cock_mensal:
#   cock.update('B29', array.tolist())

# for cel in E2E_plas:
#   cock.update('G29', arrayE2E.tolist())

# cock.update('C16', meta_mês.tolist())

"""#Alerta Diário

##Buscando arquivos do Meta
"""

alerta=pea.query('Status=="DONE"')

alerta['Mes do Pagamento']=alerta['Data de Pagamento'].str.slice(3,5)
alerta['Dia do Pagamento']=alerta['Data de Pagamento'].str.slice(0,2)
alerta['Ano do Pagamento']=alerta['Data de Pagamento'].str.slice(6,)

alerta['Mes do Pagamento']=pd.Series(alerta['Mes do Pagamento'], dtype='float')
alerta['Ano do Pagamento']=pd.Series(alerta['Ano do Pagamento'], dtype='float')
alerta['Dia do Pagamento']=pd.Series(alerta['Dia do Pagamento'], dtype='float')
alerta=alerta.query('`Ano do Pagamento`==@ano & `Mes do Pagamento`==@mes')

alerta_diario=alerta.query('`Ano do Pagamento`==@ano & `Mes do Pagamento`==@mes & `Dia do Pagamento`==@dia')

alerta_diario

"""##Buscando dados de Analise_diaria"""

AD=Analise_diaria.loc[:,['Grupo','Meta de Produção Mensal', "Modelo de Negócio",'Status','Produção semana 1','Produção semana 2', 'Produção semana 3','Produção semana 4' ]]

for i in AD.index:
  if AD['Grupo'][i]=="BANCO ABC":
    p=i
    AD['Meta de Produção Mensal'][p]=int(u)

AD['Meta Diária']=AD['Meta de Produção Mensal']/ Dias_uteis

alerta_diario=alerta_diario.groupby(['Grupo']).agg({'Valor Total':'sum'}).reset_index()

alerta_diario['Grupo']=alerta_diario['Grupo'].str.upper()

alerta_diario=pd.merge(AD, alerta_diario, how='left', on='Grupo')

alerta_diario['Valor Total']=alerta_diario['Valor Total'].fillna(0)

soma=alerta_diario['Valor Total'].sum()
soma2=alerta_diario['Meta Diária'].sum()

per_meta=(soma/soma2)*100
meta_diaria_produção=per_meta.round(2)

##tendencia, previsão, contas lucas(saas, hagana, onet, adoro e aec), Grazi(Gr, verzani e supermarket) e Fernando(end to end)
## resultado

Grazi=alerta_diario.query('Grupo=="HAGANÁ" |Grupo=="ONET"|Grupo=="FLASH COURIER" | Grupo=="VERZANI & SANDRINI S.A." | Grupo=="SUPERMARKET ALVORADA" | Grupo=="SUPERMARKET G.M.A.P" | Grupo=="SUPERMARKET PADRÃO"  | Grupo=="FORT KNOX"  | Grupo=="VERZANI - NOVAS AQUISIÇÕES"')

Fernando=alerta_diario.query('`Modelo de Negócio`=="End to End"')
###############################################################################################################################################

angeline=alerta_diario.query('Grupo in ["AXA SEGUROS", "ALPER", "BEIRA RIO SUPERMERCADOS", "BROWN FORMAN", "INVILLIA", "JUSBRASIL", "CIA MELHORAMENTOS","ARJO BRASIL", "EMICOL", "BIG DUTCHMAN", "BLOCKBIT", "GRUPO MÓDULOS", "GRUPO REDE CONTABILIDADE", "LEXMARK", "MCI", "ONYOU", "QUEIJO IPANEMA", "RICCÓ", "SAFIRA TELECOM", "TEXTE", "WM ASSESSORIA", "ATIVA ISENÇÕES", "INTERTANK", "LENDICO", "MINDBE", "REMESSA ON LINE", "ASSERTIVA","PROVU"]')

Lucas=alerta_diario.query('Grupo=="MAISTODOS" | Grupo=="GRUPO GR" | Grupo=="ADORO" | Grupo=="AEC" | `Modelo de Negócio`=="SaaS"| Grupo=="THOMSON REUTERS" | Grupo=="NAPP"')
mlprod=Lucas['Valor Total'].sum()
mlmeta=Lucas['Meta Diária'].sum()
meta_lucas=Lucas['Valor Total'].sum()/Lucas['Meta Diária'].sum()
meta_lucas=100*meta_lucas.round(2)

meta_grazi=Grazi['Valor Total'].sum()/Grazi['Meta Diária'].sum()
mgprod=Grazi['Valor Total'].sum()
mgmeta=Grazi['Meta Diária'].sum()
meta_grazi=100*meta_grazi.round(2)

mangeline=angeline['Meta Diária'].sum()
prod_angeline=angeline['Valor Total'].sum()
des_angeline=angeline['Valor Total'].sum()/angeline['Meta Diária'].sum()
des_angeline=100*des_angeline.round(2)

mfprod=Fernando['Valor Total'].sum()-prod_angeline
mfmeta=Fernando['Meta Diária'].sum()-mangeline
meta_fer=mfprod/mfmeta
meta_fer=100*meta_fer.round(2)
########################################################################################################################################

"""##Analise Mensal"""

alerta_mensal=alerta.query('`Ano do Pagamento`==@ano & `Mes do Pagamento`==@mes')

alerta_mensal=alerta_mensal.groupby(['Grupo']).agg({'Valor Total':'sum'}).reset_index()

alerta_mensal['Grupo']=alerta_mensal['Grupo'].str.upper()

alerta_mensal_merge=pd.merge(alerta_mensal,AD,how='outer')

alerta_mensal_merge['Valor Total']=alerta_mensal_merge['Valor Total'].fillna(0)

alerta_mensal_merge_mes=alerta_mensal_merge['Valor Total'].sum()/alerta_mensal_merge['Meta de Produção Mensal'].sum()
alerta_mensal_merge_mes=100*alerta_mensal_merge_mes.round(2)

soma_meta_mm=alerta_mensal_merge['Meta de Produção Mensal'].sum()

soma_mensal=alerta_mensal_merge['Valor Total'].sum()

grazi_mes=alerta_mensal_merge.query('Grupo=="HAGANÁ" |Grupo=="ONET"|Grupo=="FLASH COURIER" | Grupo=="VERZANI & SANDRINI S.A." | Grupo=="SUPERMARKET ALVORADA" | Grupo=="SUPERMARKET G.M.A.P" | Grupo=="SUPERMARKET PADRÃO"  | Grupo=="FORT KNOX"  | Grupo=="VERZANI - NOVAS AQUISIÇÕES"')
fer_mes=alerta_mensal_merge.query('`Modelo de Negócio`=="End to End"')
lucas_mes=alerta_mensal_merge.query('Grupo=="MAISTODOS" | Grupo=="GRUPO GR" | Grupo=="ADORO" | Grupo=="AEC" | `Modelo de Negócio`=="SaaS"| Grupo=="THOMSON REUTERS" | Grupo=="NAPP"')
angel_mes=alerta_mensal_merge.query('Grupo in ["AXA SEGUROS", "ALPER", "BEIRA RIO SUPERMERCADOS", "BROWN FORMAN", "INVILLIA","PROVU", "JUSBRASIL", "CIA MELHORAMENTOS","ARJO BRASIL", "EMICOL", "BIG DUTCHMAN", "BLOCKBIT", "GRUPO MÓDULOS", "GRUPO REDE CONTABILIDADE", "LEXMARK", "MCI", "ONYOU", "QUEIJO IPANEMA", "RICCÓ", "SAFIRA TELECOM", "TEXTE", "WM ASSESSORIA", "ATIVA ISENÇÕES", "INTERTANK", "LENDICO", "MINDBE", "REMESSA ON LINE", "ASSERTIVA"]')

prod_grazi_mes=grazi_mes['Valor Total'].sum()/grazi_mes['Meta de Produção Mensal'].sum()
prod_grazi_mes=100*prod_grazi_mes.round(2) 
pgm=grazi_mes['Valor Total'].sum()
mgm=grazi_mes['Meta de Produção Mensal'].sum()

prod_grazi_mes=prod_grazi_mes.round(2)

angel_prod_mes=angel_mes['Valor Total'].sum()
angel_mes_meta=angel_mes['Meta de Produção Mensal'].sum()
desem_angel_mes=angel_prod_mes/angel_mes_meta
desem_angel_mes=100*desem_angel_mes.round(2)

angel_prod_mes=angel_prod_mes.round(2)

pfm=fer_mes['Valor Total'].sum()-angel_prod_mes
mfm=fer_mes['Meta de Produção Mensal'].sum()-angel_mes_meta
prod_fer_mes=pfm/mfm
prod_fer_mes=100*(prod_fer_mes).round(2)

prod_fer_mes=(prod_fer_mes).round(2)

prod_lucas_mes=lucas_mes['Valor Total'].sum()/lucas_mes['Meta de Produção Mensal'].sum()
prod_lucas_mes=100*(prod_lucas_mes).round(2)
plm=lucas_mes['Valor Total'].sum()
mlm=lucas_mes['Meta de Produção Mensal'].sum()

prod_lucas_mes=(prod_lucas_mes).round(2)

import pytz 
IST = pytz.timezone('America/Sao_Paulo') 
# print("UTC in Default Format : ",  
#       datetime.now(UTC)) 
hora=datetime.datetime.now(IST)

hora=hora.strftime('%H')

hora

"""#Analise Semanal"""

AD['Meta semanal']=AD['Meta de Produção Mensal']/4

stms=AD['Meta semanal'].sum()

grazi_semana=AD.query('Grupo=="HAGANÁ" |Grupo=="ONET"|Grupo=="FLASH COURIER" | Grupo=="VERZANI & SANDRINI S.A." | Grupo=="SUPERMARKET ALVORADA" | Grupo=="SUPERMARKET G.M.A.P" | Grupo=="SUPERMARKET PADRÃO"  | Grupo=="FORT KNOX"  | Grupo=="VERZANI - NOVAS AQUISIÇÕES"')
fer_semana=AD.query('`Modelo de Negócio`=="End to End"')
lucas_semana=AD.query('Grupo=="MAISTODOS" | Grupo=="GRUPO GR" | Grupo=="ADORO" | Grupo=="AEC" | `Modelo de Negócio`=="SaaS"| Grupo=="THOMSON REUTERS" | Grupo=="NAPP"')
angeline_semana=AD.query('Grupo in ["AXA SEGUROS", "ALPER", "BEIRA RIO SUPERMERCADOS", "BROWN FORMAN", "INVILLIA","PROVU", "JUSBRASIL", "CIA MELHORAMENTOS","ARJO BRASIL", "EMICOL", "BIG DUTCHMAN", "BLOCKBIT", "GRUPO MÓDULOS", "GRUPO REDE CONTABILIDADE", "LEXMARK", "MCI", "ONYOU", "QUEIJO IPANEMA", "RICCÓ", "SAFIRA TELECOM", "TEXTE", "WM ASSESSORIA", "ATIVA ISENÇÕES", "INTERTANK", "LENDICO", "MINDBE", "REMESSA ON LINE", "ASSERTIVA"]')

if dia<=7:
  grazi_meta_semana=grazi_semana['Produção semana 1'].sum()/grazi_semana['Meta semanal'].sum()
  grazi_meta_sem=(grazi_meta_semana*100).round(2)
  gms=grazi_semana['Produção semana 1'].sum()
  gmm=grazi_semana['Meta semanal'].sum()
  dessemanal=AD['Produção semana 1'].sum()/stms
  somase=AD['Produção semana 1'].sum()
#ANGELINE=========================================================================================
  angel_prod_semana=angeline_semana['Produção semana 1'].sum()
  angel_meta_sema=angeline_semana['Meta semanal'].sum()
  angel_des_semana=angel_prod_semana/angel_meta_sema
  angel_des_semana=100*angel_des_semana.round(2)
#Fernando=========================================================================================
  fms=fer_semana['Produção semana 1'].sum()-angel_prod_semana
  fmm=fer_semana['Meta semanal'].sum()-angel_meta_sema
  fer_meta_semana=fms/fmm
  fer_meta_sem=(fer_meta_semana*100).round(2)
 
#Lucas============================================================================================
  lucas_meta_semana=lucas_semana['Produção semana 1'].sum()/lucas_semana['Meta semanal'].sum()
  lucas_meta_sem=(lucas_meta_semana*100).round(2)
  lms=lucas_semana['Produção semana 1'].sum()
  lmm=lucas_semana['Meta semanal'].sum()


elif dia>7 and dia<=14:
  dessemanal=AD['Produção semana 2'].sum()/stms
  somase=AD['Produção semana 2'].sum()
  grazi_meta_semana=grazi_semana['Produção semana 2'].sum()/grazi_semana['Meta semanal'].sum()
  grazi_meta_sem=(grazi_meta_semana*100).round(2)
  gms=grazi_semana['Produção semana 2'].sum()
  gmm=grazi_semana['Meta semanal'].sum()

  #ANGELINE=========================================================================================
  angel_prod_semana=angeline_semana['Produção semana 2'].sum()
  angel_meta_sema=angeline_semana['Meta semanal'].sum()
  angel_des_semana=angel_prod_semana/angel_meta_sema
  angel_des_semana=100*angel_des_semana.round(2)

  #Fernando=========================================================================================
  fms=fer_semana['Produção semana 2'].sum()-angel_prod_semana
  fmm=fer_semana['Meta semanal'].sum()-angel_meta_sema
  fer_meta_semana=fms/fmm
  fer_meta_sem=(fer_meta_semana*100).round(3)
#Lucas============================================================================================
  lucas_meta_semana=lucas_semana['Produção semana 2'].sum()/lucas_semana['Meta semanal'].sum()
  lucas_meta_sem=(lucas_meta_semana*100).round(2)
  lms=lucas_semana['Produção semana 2'].sum()
  lmm=lucas_semana['Meta semanal'].sum()

elif dia>14 and dia<=21:
  dessemanal=AD['Produção semana 3'].sum()/stms
  somase=AD['Produção semana 3'].sum()
  grazi_meta_semana=grazi_semana['Produção semana 3'].sum()/grazi_semana['Meta semanal'].sum()
  grazi_meta_sem=(grazi_meta_semana*100).round(2)
  gms=grazi_semana['Produção semana 3'].sum()
  gmm=grazi_semana['Meta semanal'].sum()
  #ANGELINE=========================================================================================
  angel_prod_semana=angeline_semana['Produção semana 3'].sum()
  angel_meta_sema=angeline_semana['Meta semanal'].sum()
  angel_des_semana=angel_prod_semana/angel_meta_sema
  angel_des_semana=100*angel_des_semana.round(2)

  #Fernando=========================================================================================
  fms=fer_semana['Produção semana 3'].sum()-angel_prod_semana
  fmm=fer_semana['Meta semanal'].sum()-angel_meta_sema
  fer_meta_semana=fms/fmm
  fer_meta_sem=(fer_meta_semana*100).round(2)
#Lucas============================================================================================
  lucas_meta_semana=lucas_semana['Produção semana 3'].sum()/lucas_semana['Meta semanal'].sum()
  lucas_meta_sem=(lucas_meta_semana*100).round(2)
  lms=lucas_semana['Produção semana 3'].sum()
  lmm=lucas_semana['Meta semanal'].sum()

elif dia>21:
  dessemanal=AD['Produção semana 4'].sum()/stms
  somase=AD['Produção semana 4'].sum()
  grazi_meta_semana=grazi_semana['Produção semana 4'].sum()/grazi_semana['Meta semanal'].sum()
  grazi_meta_sem=(grazi_meta_semana*100).round(2)
  gms=grazi_semana['Produção semana 4'].sum()
  gmm=grazi_semana['Meta semanal'].sum()
  #ANGELINE=========================================================================================
  angel_prod_semana=angeline_semana['Produção semana 4'].sum()
  angel_meta_sema=angeline_semana['Meta semanal'].sum()
  angel_des_semana=angel_prod_semana/angel_meta_sema
  angel_des_semana=100*angel_des_semana.round(2)

  #Fernando=========================================================================================
  fms=fer_semana['Produção semana 4'].sum()-angel_prod_semana
  fmm=fer_semana['Meta semanal'].sum()-angel_meta_sema
  fer_meta_semana=fms/fmm
  fer_meta_sem=(fer_meta_semana*100).round(2)
#Lucas============================================================================================
  lucas_meta_semana=lucas_semana['Produção semana 4'].sum()/lucas_semana['Meta semanal'].sum()
  lucas_meta_sem=(lucas_meta_semana*100).round(2)
  lms=lucas_semana['Produção semana 4'].sum()
  lmm=lucas_semana['Meta semanal'].sum()

dessemanal=dessemanal*100

somase

"""#Analise Mensal, Diária, Semanal"""

!pip install emoji

######################DIA
# mangeline=angeline['Meta Diária'].sum()
# prod_angeline=angeline['Valor Total'].sum()
# des_angeline=angeline['Valor Total'].sum()/angeline['Meta Diária'].sum()
# des_angeline=100*des_angeline.round(2)
#############################mes
# angel_prod_mes=angel_mes['Valor Total'].sum()
# angel_mes_meta=angel_mes['Meta de Produção Mensal'].sum()
# desem_angel_mes=angel_prod_mes/angel_mes_meta
# desem_angel_mes=100*desem_angel_mes.round(2)
#semanal
# angel_prod_semana=angeline_semana['Produção semana 4'].sum()
#   angel_meta_sema=angeline_semana['Meta semanal'].sum()
#   angel_des_semana=angel_prod_semana/angel_meta_sema
#   angel_des_semana=100*angel_des_semana.round(2)

lista_alerta=[soma2, soma, meta_diaria_produção, somase, stms, dessemanal, soma_mensal ,soma_meta_mm, alerta_mensal_merge_mes, mlmeta ,mlprod ,meta_lucas,
              lmm,lms,lucas_meta_sem,mlm,plm,prod_lucas_mes,mgmeta,mgprod,meta_grazi,gmm,gms,grazi_meta_sem,mgm,pgm,prod_grazi_mes,mfmeta,mfprod,meta_fer,fmm,fms,fer_meta_sem,mfm,pfm,prod_fer_mes,mangeline,prod_angeline,des_angeline,angel_prod_mes,angel_mes_meta,desem_angel_mes,angel_prod_semana,angel_meta_sema,angel_des_semana]

notas=[soma2, soma, meta_diaria_produção, somase, stms, dessemanal, soma_mensal ,soma_meta_mm, alerta_mensal_merge_mes, mlmeta ,mlprod ,meta_lucas,
              lmm,lms,lucas_meta_sem,mlm,plm,prod_lucas_mes,mgmeta,mgprod,meta_grazi,gmm,gms,grazi_meta_sem,mgm,pgm,prod_grazi_mes,mfmeta,mfprod,meta_fer,fmm,fms,fer_meta_sem,mfm,pfm,prod_fer_mes,mangeline,prod_angeline,des_angeline,angel_prod_mes,angel_mes_meta,desem_angel_mes,angel_prod_semana,angel_meta_sema,angel_des_semana]
for i in range(len(lista_alerta)):
  lista_alerta[i]=lista_alerta[i].round(1)
for i in range(len(lista_alerta)):
  if lista_alerta[i]>=1000 and lista_alerta[i]<1000000:
      lista_alerta[i]=lista_alerta[i]/1000
      lista_alerta[i]=lista_alerta[i].round(1)
      lista_alerta[i]=str(lista_alerta[i])+" K"
  elif lista_alerta[i]>=1000000:
      lista_alerta[i]=lista_alerta[i]/1000000
      lista_alerta[i]=lista_alerta[i].round(1)
      lista_alerta[i]=str(lista_alerta[i])+" M"

soma2= lista_alerta[0]
soma= lista_alerta[1]
meta_diaria_produção = lista_alerta[2]
somase = lista_alerta[3]
stms = lista_alerta[4]
dessemanal= lista_alerta[5]
soma_mensal = lista_alerta[6]
soma_meta_mm = lista_alerta[7]
alerta_mensal_merge_mes= lista_alerta[8] 
mlmeta = lista_alerta[9]
mlprod = lista_alerta[10]
meta_lucas= lista_alerta[11]
lmm= lista_alerta[12]
lms= lista_alerta[13]
lucas_meta_sem= lista_alerta[14]
mlm= lista_alerta[15]
plm= lista_alerta[16]
prod_lucas_mes= lista_alerta[17]
mgmeta= lista_alerta[18]
mgprod= lista_alerta[19]
meta_grazi= lista_alerta[20]
gmm= lista_alerta[21]
gms= lista_alerta[22]
grazi_meta_sem= lista_alerta[23]
mgm= lista_alerta[24]
pgm= lista_alerta[25]
prod_grazi_mes= lista_alerta[26]
mfmeta= lista_alerta[27]
mfprod= lista_alerta[28]
meta_fer= lista_alerta[29]
fmm= lista_alerta[30]
fms= lista_alerta[31]
fer_meta_sem= lista_alerta[32]
mfm= lista_alerta[33]
pfm= lista_alerta[34]
prod_fer_mes= lista_alerta[35]
mangeline= lista_alerta[36]
prod_angeline= lista_alerta[37]
des_angeline= lista_alerta[38]
angel_prod_mes= lista_alerta[39]
angel_mes_meta= lista_alerta[40]
desem_angel_mes= lista_alerta[41]
angel_prod_semana= lista_alerta[42]
angel_meta_sema= lista_alerta[43]
angel_des_semana= lista_alerta[44]

Linhas='\U0001F680EMPRESA \U0001F474LUCAS \U0001F469GRAZI \U0001F9D1FERNANDO'.split()
Colunas='META PRODUÇÃO DESEMPENHO'.split()

foguete='\U0001F680'
Lucas='\U0001F474'
Grazi='\U0001F469'
Fernando='\U0001F9D1'
ponto=''
Angeline='\U0001F9D1'

Fernando

litf=[lista_alerta[2], lista_alerta[10], lista_alerta[20], lista_alerta[29], lista_alerta[5], lista_alerta[14], lista_alerta[23], lista_alerta[32], lista_alerta[8], lista_alerta[17], lista_alerta[26], lista_alerta[35],lista_alerta[38],lista_alerta[41],lista_alerta[44]]
ori=''
lucs=''
gra=''
fer=''
oris=''
fers=''
orim=''
lucasm=''
gram=''
ferm=''
angeld=''
angels=''
angelm=''
########################################
if lista_alerta[2] <=50:
  ori='\U0001F534'
if 50<lista_alerta[2]<=80:
  ori='\U0001F7E1'
if lista_alerta[2]>=80:
  ori='\U0001F7E2'
########################################
if lista_alerta[8] <=50:
  orim='\U0001F534'
if 50<lista_alerta[8]<=80:
  orim='\U0001F7E1'
if lista_alerta[8]>=80:
  orim='\U0001F7E2'
########################################
if lista_alerta[17] <=50:
  lucasm='\U0001F534'
if 50<lista_alerta[17]<=80:
  lucasm='\U0001F7E1'
if lista_alerta[17]>=80:
  lucasm='\U0001F7E2'
########################################
if lista_alerta[26] <=50:
  gram='\U0001F534'
if 50<lista_alerta[26]<=80:
  gram='\U0001F7E1'
if lista_alerta[26]>=80:
  gram='\U0001F7E2'
########################################
if lista_alerta[35] <=50:
  ferm='\U0001F534'
if 50<lista_alerta[35]<=80:
  ferm='\U0001F7E1'
if lista_alerta[35]>=80:
  ferm='\U0001F7E2'
######################################
if lista_alerta[11] <=50:
   lucs='\U0001F534'
if 50<lista_alerta[11]<=80:
  lucs='\U0001F7E1'
if lista_alerta[11]>=80:
  lucs='\U0001F7E2'
######################################
if lista_alerta[20] <=50:
  gra='\U0001F534'
if 50<lista_alerta[20]<=80:
  gra='\U0001F7E1'
if lista_alerta[20]>=80:
  gra='\U0001F7E2'
#######################################
if lista_alerta[29] <=50:
  fer='\U0001F534'
if 50<lista_alerta[29]<=80:
  fer='\U0001F7E1'
if lista_alerta[29]>=80:
  fer='\U0001F7E2'
##################################
if lista_alerta[5] <=50:
  oris='\U0001F534'
if 50<lista_alerta[5]<=80:
  oris='\U0001F7E1'
if lista_alerta[5]>=80:
  oris='\U0001F7E2'
#####################################
lucass=''
if lista_alerta[14] <=50:
  lucass='\U0001F534'
if 50<lista_alerta[14]<=80:
  lucass='\U0001F7E1'
if lista_alerta[14]>=80:
  lucass='\U0001F7E2'
#####################################
grazis=''
if lista_alerta[23] <=50:
  grazis='\U0001F534'
if 50<lista_alerta[23]<=80:
  grazis='\U0001F7E1'
if lista_alerta[23]>=80:
  grazis='\U0001F7E2'
#####################################
fers=''
if lista_alerta[32] <=50:
  fers='\U0001F534'
if 50<lista_alerta[32]<=80:
  fers='\U0001F7E1'
if lista_alerta[32]>=80:
  fers='\U0001F7E2'
#####################################
if lista_alerta[38] <=50:
  angeld='\U0001F534'
if 50<lista_alerta[38]<=80:
  angeld='\U0001F7E1'
if lista_alerta[38]>=80:
  angeld='\U0001F7E2'
######################################
if lista_alerta[41] <=50:
  angelm='\U0001F534'
if 50<lista_alerta[41]<=80:
  angelm='\U0001F7E1'
if lista_alerta[41]>=80:
  angelm='\U0001F7E2'
######################################
if lista_alerta[44] <=50:
  angels='\U0001F534'
if 50<lista_alerta[44]<=80:
  angels='\U0001F7E1'
if lista_alerta[44]>=80:
  angels='\U0001F7E2'

Linhas=['\U0001F680EMPRESA','\U0001F474LUCAS','\U0001F469GRAZI','\U0001F9D1FERNANDO']
Colunas='META PRODUÇÃO DESEMPENHO'.split()
pont="          "
tru="         "



# Commented out IPython magic to ensure Python compatibility.
import json
import requests
import os
#Set the webhook_url to the one provided by Slack when you create the webhook at https://my.slack.com/services/new/incoming-webhook/
webhook_url = 'https://hooks.slack.com/services/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'
if hora>="14":
  slack_data ={

    "blocks": [
      {
        "type": "header",
        "text": {
          "type": "plain_text",
          "text": "==========================================\n\t\t\t\t\t\t\t\t\t                       \t\t\t\t\t\t\t\t\tDIÁRIO\n==========================================",
          "emoji": True
        }
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{foguete}*EMPRESA*"
        }
      },
      {
        "type": "section",
        "fields":[
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[0]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[1]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[2]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{ori}"
          }
          ,
          
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Lucas}*LUCAS*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[9]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[10]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[11]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{lucs}"
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Grazi}*GRAZI*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[18]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[19]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[20]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{gra}"
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Fernando}*FERNANDO*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[27]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[28]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[29]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{fer}"
          },
        ]
        },
           {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Angeline}*ANGELINE*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[36]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[37]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[38]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{angeld}"
          }
          
        ]
      }
    ]
  }
  
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )
  if response.status_code != 200:
        raise ValueError(
            'Request to slack returned an error %s, the response is:\n%s'
#             % (response.status_code, response.text)
        )
  slack_data = {'text':f''}
    
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )

if dia <=7:
  dta_dia=dia
elif dia>7 and dia<=14 :
  dta_dia=dia-7
elif dia>14 and dia <=21:
  dta_dia=dia-14
elif dia>21:
  dta_dia=dia-21

if dta_dia==0:
  dta_dia=1

previsao_semanal_emp=notas[3]/dta_dia
previsao_semanal_emp=previsao_semanal_emp*7

previsao_semanal_lucas=notas[13]/dta_dia
previsao_semanal_lucas=previsao_semanal_lucas*7

previsao_semanal_grazi=notas[22]/dta_dia
previsao_semanal_grazi=previsao_semanal_grazi*7

previsao_semanal_fernando=notas[31]/dta_dia
previsao_semanal_fernando=previsao_semanal_fernando*7

prevision_semanal_angel=notas[42]/dta_dia
prevision_semanal_angel=prevision_semanal_angel*7

Prevision_semanal=[previsao_semanal_emp,previsao_semanal_lucas,previsao_semanal_grazi,previsao_semanal_fernando,prevision_semanal_angel]



for i in range(len(Prevision_semanal)):
  if Prevision_semanal[i]>=1000 and Prevision_semanal[i]<1000000:
      Prevision_semanal[i]=Prevision_semanal[i]/1000
      Prevision_semanal[i]=Prevision_semanal[i].round(1)
      Prevision_semanal[i]=str(Prevision_semanal[i])+" K"
  elif Prevision_semanal[i]>=1000000:
      Prevision_semanal[i]=Prevision_semanal[i]/1000000
      Prevision_semanal[i]=Prevision_semanal[i].round(3)
      Prevision_semanal[i]=str(Prevision_semanal[i])+" M"

# Commented out IPython magic to ensure Python compatibility.
webhook_url = 'https://hooks.slack.com/services/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'
if hora>="15":
  slack_data ={

    "blocks": [
      {
        "type": "header",
        "text": {
          "type": "plain_text",
          "text": "==========================================\n\t\t\t\t\t\t\t\t\t                       \t\t\t\t\t\t\t\t\tSEMANAL\n==========================================",
          "emoji": True
        }
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{foguete}*EMPRESA*"
        }
      },
      {
        "type": "section",
        "fields":[
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[4]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[3]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[5]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{oris}"
            
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO SEMANAL*\n{Prevision_semanal[0]}"
            
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Lucas}*LUCAS*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[12]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[13]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[14]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{lucass}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO SEMANAL*\n{Prevision_semanal[1]}"
            
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Grazi}*GRAZI*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[21]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[22]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[23]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{grazis}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO SEMANAL*\n{Prevision_semanal[2]}"
            
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Fernando}*FERNANDO*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[30]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[31]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[32]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{fers}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO SEMANAL*\n{Prevision_semanal[3]}"
            
          },
          ]
      },
           {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Angeline}*ANGELINE*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[43]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[42]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[44]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{angels}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO SEMANAL*\n{Prevision_semanal[4]}"
            
          }
          
        ]
      }
    ]
  }
   
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )
  if response.status_code != 200:
        raise ValueError(
            'Request to slack returned an error %s, the response is:\n%s'
#             % (response.status_code, response.text)
        )
  slack_data = {'text':f''}
    
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )

previsão_empresa=notas[6]/Dias_uteis_hoje
previsão_empresa=previsão_empresa*Dias_uteis

previsão_lucas=notas[16]/Dias_uteis_hoje
previsão_lucas=previsão_lucas*Dias_uteis

previsão_grazi=notas[25]/Dias_uteis_hoje
previsão_grazi=previsão_grazi*Dias_uteis

previsão_fernando=notas[34]/Dias_uteis_hoje
previsão_fernando=previsão_fernando*Dias_uteis

previsão_angeline_mes=notas[39]/Dias_uteis_hoje
previsão_angeline_mes=previsão_angeline_mes*Dias_uteis



Prevision=[previsão_empresa,previsão_lucas,previsão_grazi,previsão_fernando,previsão_angeline_mes]

for i in range(len(Prevision)):
  if Prevision[i]>=1000 and Prevision[i]<1000000:
      Prevision[i]=Prevision[i]/1000
      Prevision[i]=Prevision[i].round(1)
      Prevision[i]=str(Prevision[i])+" K"
  elif Prevision[i]>=1000000:
      Prevision[i]=Prevision[i]/1000000
      Prevision[i]=Prevision[i].round(3)
      Prevision[i]=str(Prevision[i])+" M"

# Commented out IPython magic to ensure Python compatibility.
webhook_url = 'https://hooks.slack.com/services/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'
if hora>="15":
  slack_data ={

    "blocks": [
      {
        "type": "header",
        "text": {
          "type": "plain_text",
          "text": "==========================================\n\t\t\t\t\t\t\t\t\t                       \t\t\t\t\t\t\t\t\tMENSAL\n==========================================",
          "emoji": True
        }
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{foguete}*EMPRESA*"
        }
      },
      {
        "type": "section",
        "fields":[
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[7]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[6]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[8]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{orim}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{Prevision[0]}"
          }
         
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Lucas}*LUCAS*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[15]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[16]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[17]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{lucasm}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{Prevision[1]}"
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Grazi}*GRAZI*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[24]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[25]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[26]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{gram}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{Prevision[2]}"
          }
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Fernando}*FERNANDO*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[33]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[34]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[35]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{ferm}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{Prevision[3]}"
          },
          ]
      },
           {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{Angeline}*ANGELINE*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{lista_alerta[40]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{lista_alerta[39]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{lista_alerta[41]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{angelm}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{Prevision[4]}"
          }
        ]
      }
    ]
  }

  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )
  if response.status_code != 200:
        raise ValueError(
            'Request to slack returned an error %s, the response is:\n%s'
#             % (response.status_code, response.text)
        )
  slack_data = {'text':f''}
    
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )

"""#Tempo decorrido da solicitação ao pagamento"""

import statistics as st

tempod=tempo.loc[:,['Grupo','Fundo', 'CPF', 'Salário Líquido', 'Valor Total', 'Status', 'Data de Pagamento', 'Dispensar Averbação', 'Data da Solicitação', 'Modelo de negócio']]

tempod['Mes de Pagamento']=tempod['Data de Pagamento'].str.slice(3,)

tempod=tempod.query('`Mes de Pagamento`==@data_atual')

tempod['Data Solicitação']=tempod['Data da Solicitação'].apply(lambda x: re.sub("/","",x))

tempod['Data de Pagamento']=tempod['Data de Pagamento'].fillna('')

tempod['Data Pagamento']=tempod['Data de Pagamento'].apply(lambda x: re.sub("/","",x))

tempod['Data Solicitação']=tempod['Data Solicitação'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date())

tempod['Data Pagamento']=tempod['Data Pagamento'].apply(lambda x: datetime.datetime.strptime(x, "%d%m%Y").date() if x!='' else x)

tempod['Data Pagamento']=pd.to_datetime(tempod['Data Pagamento'])

tempod['Data Solicitação']=pd.to_datetime(tempod['Data Solicitação'])

tempod['Dias entre solicitação e pagamento']=tempod['Data Pagamento']-tempod['Data Solicitação']

tempod['Dias entre solicitação e pagamento']=pd.Series(tempod['Dias entre solicitação e pagamento'], dtype="string")

tempod['Dias entre solicitação e pagamento']=tempod['Dias entre solicitação e pagamento'].str.slice(0,2)

tempod['Dias entre solicitação e pagamento']=pd.to_numeric(tempod['Dias entre solicitação e pagamento'])
tempod.drop(tempod.loc[tempod['Dias entre solicitação e pagamento']<=0].index, inplace=True)

mean_df=tempod['Dias entre solicitação e pagamento'].describe()
mean_df=pd.DataFrame(mean_df).reset_index()
tempod=tempod.fillna(0)

ticketmedio=tempod['Valor Total'].sum()/tempod['Status'].count()

if ticketmedio!=float:
 ticketmedio=1
else:
 ticketmedio=int(ticketmedio)

ticketmedio

mean_df['index']=mean_df['index'].str.upper()

mean_df=mean_df.rename(columns={'index':'Estatistica'})

mean_df=mean_df.drop(mean_df.index[[4,5,6]])

mean_df=mean_df.fillna(0)

mean_df

ESTATISTICA=Dp.worksheet('INFORMAÇÕES SOBRE TEMPO DE')
ESTATISTICA.update([mean_df.columns.values.tolist()]+ mean_df.values.tolist())
ESTATISTICA.update('B7', f'{ticketmedio}')
#E2E_clas=([E2E.columns.values.tolist()]+E2E.values.tolist())
# cock_mensal= cock.range('B29:D32')
# E2E_plas=cock.range('F30:H33')
# arrayE2E=np.array(E2E_clas)
# array = np.array(cockup)

# for cells in cock_mensal:
#   cock.update('B29', array.tolist())

# for cel in E2E_plas:
#   cock.update('G29', arrayE2E.tolist())

# cock.update('C16', meta_mês.tolist())

"""#Controle do Angeline

##PROPOSTAS
"""

cr= gc.open_by_url('https://docs.google.com/spreadsheets/d/1OYa9v0yu5qiDMcnu1iv1zgixLqtG5xWVbvG0O6EyN6g/edit#gid=915287314')
bc=cr.worksheet('Status por cpf')
vang=cr.worksheet('SImulações com valor')
Simu_valor=pd.read_json(f"{caminho10}/{arquivo10}")
Simuftr=pd.read_json(f"{caminho10}/{arquivo10}",dtype={'cpf': str})

bc.clear()
vang.clear()

angel=angel.loc[:,['CPF NORMALIZADO', 'Valor Total', 'Data da Solicitação', 'Data de Pagamento', 'Status', 'Valor solicitado']]

angel['Mes Solicitação']=angel['Data da Solicitação'].str.slice(3,)

angel['Mes Pagamento']=angel['Data de Pagamento'].str.slice(3,)

data_mesA=str('0')+str(mes-1)+'/'+str(ano)

track=angel.query('`Mes Solicitação`==@data_atual|`Mes Pagamento`==@data_atual |`Mes Solicitação`==@data_mesA |`Mes Pagamento`==@data_mesA')

track['Semana']=pd.to_datetime(track['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%U"))

track['Valor Total']=track['Valor Total'].fillna(0)
track.drop(['Mes Solicitação', 'Mes Pagamento'], inplace=True, axis=1)

track=track.fillna('')

bc.update([track.columns.values.tolist()]+ track.values.tolist())

track.drop(['Semana'], inplace=True,axis=1)

"""##SIMULAÇÔES"""

Simu_valor['updatedAt']=pd.Series(Simu_valor['updatedAt'], dtype="string")

Simu_valor['updatedAt']=Simu_valor['updatedAt'].str.slice(0,10)

Simu_valor['dia']=Simu_valor['updatedAt'].str.slice(8,)

Simu_valor=Simu_valor.fillna('')

Simu_valor['Mes']=Simu_valor['updatedAt'].str.slice(5,7)

Simu_valor['Ano']=Simu_valor['updatedAt'].str.slice(0,4)

Simu_valor=Simu_valor.drop_duplicates(subset=['cpf','dia','Mes','Ano'])

Simu_valor

Simu_valor['Mes']=pd.to_numeric(Simu_valor['Mes'])

Simu_valor['Ano']=pd.to_numeric(Simu_valor['Ano'])
Simu_valor=Simu_valor.query('Ano==@ano')

desc=Simu_valor.query('Mes==@mes|Mes==@mes1')

desc=desc.rename(columns={'company':'Empresa'})

desc=desc.loc[:,['cpf','value','Empresa','updatedAt','paketa_users → name','Mes']]

desc["Semana do Ano"]=pd.to_datetime(desc['updatedAt']).apply(lambda x: datetime.datetime.strftime(x, "%U"))

vang.update([desc.columns.values.tolist()]+ desc.values.tolist())

desc.drop(['Semana do Ano'],inplace=True,axis=1)

"""#Todas As Simulações Base de 350 mb, calculado para um determinado fim

"""

# caminho12='/content/drive/Othercomputers/Meu laptop/Todas as simulações desde sempre, para sempre que precisa'
# lista_arquivos12= os.listdir(caminho12)
# lista_datas12= []
# for arquivo in lista_arquivos12:
#   #descobrir data do arquivo
#   data=os.path.getmtime(f"{caminho12}/{arquivo}")
#   lista_datas12.append((data, arquivo))

# lista_datas12.sort(reverse=True)
# ultimo_arquivo12= lista_datas12[0]
# arquivo12=ultimo_arquivo12[1]

# calcr=pd.read_csv(f"{caminho12}/{arquivo12}")

# pcc=calcr.loc[:,['cpf','company','user']]

# pcc=pcc.drop_duplicates(subset = "cpf")

# dpcc=pcc.groupby(['company']).agg({'cpf':'count'}).reset_index()

# dpcc=dpcc.rename(columns={'company':'Empresa'})

# dpcc=dpcc.fillna('')

# dpcc=pd.merge(dpcc,vap,how='left', on='Empresa')

# dpcc.to_excel('filename.xlsx') 
# files.download('filename.xlsx')

optins=pea.loc[:,['Grupo', 'Valor Total', 'Status', 'Data de Pagamento', 'Modelo de negócio']]
optins1=optins.query('Status=="DONE"')
optins1['Ano']=pd.to_numeric(optins1['Data de Pagamento'].str.slice(6,))

optins2=optins1.query('Ano==@ano')

optins2['Mes']=pd.to_numeric(optins2['Data de Pagamento'].str.slice(3,5))

optins2['Janeiro']=optins2.loc[(optins2['Mes']==1),['Valor Total']]
optins2['Fevereiro']=optins2.loc[(optins2['Mes']==2),['Valor Total']]
optins2['Março']=optins2.loc[(optins2['Mes']==3),['Valor Total']]
optins2['Abril']=optins2.loc[(optins2['Mes']==4),['Valor Total']]
optins2['Maio']=optins2.loc[(optins2['Mes']==5),['Valor Total']]
optins2['Junho']=optins2.loc[(optins2['Mes']==6),['Valor Total']]
optins2['Julho']=optins2.loc[(optins2['Mes']==7),['Valor Total']]
optins2['Agosto']=optins2.loc[(optins2['Mes']==8),['Valor Total']]
optins2['Setembro']=optins2.loc[(optins2['Mes']==9),['Valor Total']]
optins2['Outubro']=optins2.loc[(optins2['Mes']==10),['Valor Total']]
optins2['Novembro']=optins2.loc[(optins2['Mes']==11),['Valor Total']]
optins2['Dezembro']=optins2.loc[(optins2['Mes']==12),['Valor Total']]

optins2=optins2.fillna(0)

optins3=optins2.groupby(['Grupo']).agg({'Janeiro':'sum', 'Fevereiro':'sum', 'Março':'sum','Abril':'sum', 'Maio':'sum', 'Junho':'sum','Julho':'sum','Agosto':'sum', 'Setembro':'sum', 'Outubro':'sum', 'Novembro':'sum', 'Dezembro':'sum'}).reset_index()

ad1=AD.loc[:,['Grupo','Modelo de Negócio']]

optins3['Grupo']=optins3['Grupo'].str.upper()

optins4=pd.merge(optins3,ad1,how='left', on='Grupo')

meta_total=meta[['Grupo','Janeiro',	'Fevereiro',	'Março',	'Abril',	'Maio',	'Junho',	'Julho',	'Agosto',	'Setembro',	'Outubro','Novembro',	'Dezembro']]

dados_total=pd.DataFrame.from_dict(dados_sass)

dados_total=dados_total[[0,1,2,3,4,5,6,7,8,9,10,11,12]]

dados_total.columns=dados_total.iloc[0]

dados_total=dados_total.rename(columns={"":"Produto"})

dados_total=dados_total.query('Produto=="SaaS"')

listar=pd.concat([meta_total,dados_total])

listar.drop(['Produto'], axis=1, inplace=True)

listar['Grupo']=listar['Grupo'].fillna('BANCO ABC')

listar['Grupo']=pd.Series(listar['Grupo'], dtype='string')
listar['Janeiro']=pd.Series(listar['Janeiro'], dtype='string')

listar['Janeiro']=listar['Janeiro'].str.slice(2,)
listar['Fevereiro']=listar['Fevereiro'].str.slice(2,)
listar['Março']=listar['Março'].str.slice(2,)
listar['Maio']=listar['Maio'].str.slice(2,)
listar['Junho']=listar['Junho'].str.slice(2,)
listar['Agosto']=listar['Agosto'].str.slice(2,)
listar['Setembro']=listar['Setembro'].str.slice(2,)
listar['Outubro']=listar['Outubro'].str.slice(2,)
listar['Novembro']=listar['Novembro'].str.slice(2,)
listar['Dezembro']=listar['Dezembro'].str.slice(2,)

listar['Abril']=listar['Abril'].str.slice(2,)

listar['Julho']=listar['Julho'].str.slice(2,)

listar['Grupo']=listar['Grupo'].str.upper()

listar=pd.merge(listar,ad1,how='left',on='Grupo')

listar=listar.rename(columns={'Janeiro':'Meta Janeiro','Fevereiro':'Meta Fevereiro','Março':'Meta Março','Abril':'Meta Abril',	'Maio':'Meta Maio','Junho':'Meta Junho','Julho':'Meta Julho','Agosto':'Meta Agosto','Setembro':'Meta setembro','Outubro':'Meta Outubro','Novembro':'Meta Novembro','Dezembro':'Meta Dezembro'})



Dp= gc.open_by_url('https://docs.google.com/spreadsheets/d/1bFeLNz-SbWdUQKGu1LApxF0yueYV3tQMJFa2TQti_YY/edit#gid=168572371')
Hp=Dp.worksheet('Histório de Produção em cada mes')
Pare=gc.open_by_url('https://docs.google.com/spreadsheets/d/1BfSCioFUnTM20hJkkPxcUchBrT07zr_4xl5EidwY--Y/edit#gid=1236756648')
par=Pare.worksheet('Produção/Mes')
Hp.clear()
par.clear()
Hp.update([optins4.columns.values.tolist()]+optins4.values.tolist())
par.update([optins4.columns.values.tolist()]+optins4.values.tolist())

dt_meta=Dp.worksheet('META TOTAL ANUAL')

dt_meta.update([listar.columns.values.tolist()]+listar.values.tolist())

"""#PROPOSTAS COM VALOR ALTO

"""

simuptd=pd.read_csv((f"{caminho4}/{arquivo4}"),dtype={'CPF': str})
Prop_5000=simuptd[['Grupo','Celular','Data','CPF','Nome','CNPJ']]

Prop_5000['Data']=pd.to_datetime(Prop_5000['Data'],format="%d/%m/%Y")

today=date.today()

Prop_5000=Prop_5000.query('Data==@today')

Simu_5000=Simuftr[['cpf','value','updatedAt']]

Simu_5000['updatedAt']=pd.to_datetime(Simu_5000['updatedAt'],format='%Y-%m-%d').apply(lambda x: x.date())

Simu_5000=Simu_5000.drop_duplicates()

Simu_5000=Simu_5000.query('updatedAt==@today')

Simu_5000=Simu_5000.rename(columns={'cpf':'CPF','value':'Valor','updateAt':'Data Solicitação'})

simu_prop_5000=pd.merge(Prop_5000,Simu_5000,how='left', on='CPF')

simu_prop_5000['Grupo']=simu_prop_5000['Grupo'].str.upper()

ADE=AD[['Grupo','Status','Modelo de Negócio']]

cnpjs_ange=gc.open_by_url('https://docs.google.com/spreadsheets/d/10g-gZCx8bgznCnQUfLgHcmaAfRG6Y2lDxOtc01rYcp4/edit#gid=0')
angel_cn= cnpjs_ange.worksheet('CNPJS')
dados_cn= angel_cn.get_all_records()
cnpj_ange= pd.DataFrame(dados_cn)

cnpj_ange=cnpj_ange[['CNPJ']]

simu_prop_5000=pd.merge(cnpj_ange,simu_prop_5000,how='left',on='CNPJ')

simu_prop_5000['Valor']=simu_prop_5000['Valor'].fillna(0)
simu_prop_5000=simu_prop_5000.query('Valor !=0')

simu_prop_5000=pd.merge(simu_prop_5000,ADE,how='left', on='Grupo')

simu_prop_5000=simu_prop_5000.query('`Modelo de Negócio`!="SaaS"')

simu_prop_5000.drop(['Data','updatedAt'],inplace=True,axis=1)

simu_prop_5000=simu_prop_5000.query('Grupo!="GRUPO GR"')

anexo=simu_prop_5000.to_html()

import smtplib
import email.message
if hora>='08' and hora<='15':
 def enviar_email():  
    corpo_email = f"""
    <p>{anexo}</p>
   
    <p>Parágrafo2</p>
    """
   
    msg = email.message.Message()
    
    msg['Subject'] = "Simulações + 5000"
    msg['From'] = 'iuri.silva@paketa.com.br'
    msg['To'] = 'rafael.angelini@paketa.com.br'
    password = 'drvsgqxlpnybtins' 
    msg.add_header('Content-Type', 'text/html')
    msg.set_payload(corpo_email )

    s = smtplib.SMTP('smtp.gmail.com: 587')
    s.starttls()
    # Login Credentials for sending the mail
    s.login(msg['From'], password)
    s.sendmail(msg['From'], [msg['To']], msg.as_string().encode('utf-8'))
    print('Email enviado')

if hora>='08' and hora<='15':
 enviar_email()

simu_prop_5000=simu_prop_5000.fillna('')

comecar=cr.worksheet('Propostas Maiores que 5000')
comecar.clear()
comecar.update([simu_prop_5000.columns.values.tolist()]+ simu_prop_5000.values.tolist())

"""#REVISÂO DE CONTAS TEMPLATE


"""

pea['Ano da Solicitação']=pd.to_numeric(pea['Data da Solicitação'].str.slice(6,))
pea['Mes da Solcitação']=pd.to_numeric(pea['Data da Solicitação'].str.slice(3,5))
pea['Ano do Pagamento']=pd.to_numeric(pea['Data de Pagamento'].str.slice(6,))
pea['Mes do Pagamento']=pd.to_numeric(pea['Data de Pagamento'].str.slice(3,5))

calc_ano=pea.query('`Ano da Solicitação`==@ano | `Ano do Pagamento`==@ano ')

calc_ano['Em ánalise']=calc_ano['Status'].apply(where)

em_analise=calc_ano.query('`Em ánalise`!=0')

Qtd_pagas=optins2['Valor Total'].count()

#ANO
tds_propostas=calc_ano['Valor Total'].sum()
media_tds_propostas=tds_propostas/mes
em_analise_ano=em_analise['Valor Total'].sum()
media_em_analise_ano=em_analise_ano/mes
Soma_done=optins2['Valor Total'].sum()
media_done=Soma_done/mes
Qtd_simu=Simu_valor['cpf'].count()
media_Qtd_simu=Qtd_simu/mes
Qtd_prop=calc_ano['CPF NORMALIZADO'].count()
media_Qtd_prop=Qtd_prop/mes
Qtd_em_analise=em_analise['CPF NORMALIZADO'].count()
media_Qtd_em_analise=Qtd_em_analise/mes
Qtd_pagas=optins2['Valor Total'].count()
media_Qtd_pagas=Qtd_pagas/mes

tabela_anual=pd.DataFrame(data={
                                    'Propriedades':['Valor R$','Quantidade', 'Media R$ Anual', 'Quantidade media' ],
                                    
                                   'Simulações':[0,int(Qtd_simu),0,int(media_Qtd_simu)],
                                    
                                   'Propostas':[tds_propostas.round(),Qtd_prop.round(),media_tds_propostas.round(),media_Qtd_prop.round()],
                                   
                                   'Em Análise':[em_analise_ano.round(),Qtd_em_analise.round(),media_em_analise_ano.round(),media_Qtd_em_analise.round()],
                                                 
                                   'Pagas' : [Soma_done.round(),Qtd_pagas.round(),media_done.round(),media_Qtd_pagas.round()],
                                   
}
                          )

pagas_mes=optins2.query('Mes==@mes')

prop_mes_sol=calc_ano.query('`Mes da Solcitação`==@mes | `Mes do Pagamento`==@mes')

em_analise_mes=prop_mes_sol.query('`Em ánalise`!=0')

simu_mes=Simu_valor.query('Mes==@mes')

solicitadas_mes=prop_mes_sol['Valor Total'].sum()
qtd_solicitadas_mes=prop_mes_sol['Nome'].count()
pg_mes=pagas_mes['Valor Total'].sum()
qtd_mes_done=pagas_mes['Status'].count()
pg_em_analise_mes=em_analise_mes['Valor Total'].sum()
qtd_em_analise_mes=em_analise_mes['Nome'].count()
qtd_simu_mes=simu_mes['cpf'].count()

tabela_mes=pd.DataFrame(data={
                                    'Propriedades':['Valor R$','Quantidade'],
                                    
                                   'Simulações':[0,qtd_simu_mes.round()],
                                    
                                   'Propostas':[solicitadas_mes.round(),qtd_solicitadas_mes.round()],
                                   
                                   'Em Análise':[pg_em_analise_mes.round(),qtd_em_analise_mes.round()],
                                                 
                                   'Pagas' : [pg_mes.round(),qtd_mes_done.round()],
                                   
}
                          )

ESTATISTICA=Dp.worksheet('INFORMAÇÕES SOBRE TEMPO DE')
estat_c=ESTATISTICA.range('D2:Z100')
arrayx=np.array(tabela_anual)

arraym=np.array(tabela_mes)
pori=[1]
for sts in pori:
  ESTATISTICA.update('D2', arrayx.tolist())

for sts in pori:
  ESTATISTICA.update('D8', arraym.tolist())

"""#Simulações no mês CS-OPS por grupo-TEMPLATE

##MES
"""

simu_ops=simu_mes[['value','paketa_groups → name','paketa_companies - company → cnpj','paketa_users → name']]

simu_ops=simu_ops.rename(columns={'value':'Valor Simulado', 'paketa_groups → name':'Grupo','paketa_companies - company → cnpj':'CNPJ','paketa_users → name':'Nome'})

simu_ops['Nome']=simu_ops['Nome'].apply(lambda x: 1 if x!=1 else x)

simula_mes=simu_ops.groupby(['Grupo']).agg({'Valor Simulado':'sum','Nome':'sum'}).reset_index()
simula_mes['Grupo']=simula_mes['Grupo'].str.upper()

simula_mes=pd.merge(simula_mes,ADE,how='left', on='Grupo')

simula_mes['Modelo de Negócio']=simula_mes['Modelo de Negócio'].fillna('SaaS')
simula_mes['Status']=simula_mes['Status'].fillna('ATIVO')
simula_mes=simula_mes.rename(columns={'Nome':'Quantidade Simulada'})

spk=Dp.worksheet('Simulações por Grupo\mes')
cell_list = spk.range("A1:E500")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
spk.update_cells(cell_list)
spk.update([simula_mes.columns.values.tolist()] + simula_mes.values.tolist())

"""##ANO

"""

Simu_Ano=Simu_valor[['value','paketa_groups → name','paketa_users → name']]

Simu_Ano=Simu_Ano.rename(columns={'value':'Valor Simulado', 'paketa_groups → name':'Grupo','paketa_users → name':'Quantidade Simulada'})

Simu_Ano['Quantidade Simulada']=Simu_Ano['Quantidade Simulada'].apply(lambda x: 1 if x!=1 else x)

Simu_ano=Simu_Ano.groupby(['Grupo']).agg({'Valor Simulado':'sum','Quantidade Simulada':'sum'}).reset_index()
Simu_ano['Grupo']=Simu_ano['Grupo'].str.upper()
ADE=AD[['Grupo','Status','Modelo de Negócio']]

Simu_ano=pd.merge(Simu_ano,ADE,how='left', on='Grupo')

Simu_ano['Modelo de Negócio']=Simu_ano['Modelo de Negócio'].fillna('SaaS')
Simu_ano['Status']=Simu_ano['Status'].fillna('ATIVO')

smap=Dp.worksheet('Simulação Por Grupo/ANO')
cell_list = smap.range("A1:E500")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
smap.update_cells(cell_list)
smap.update([Simu_ano.columns.values.tolist()] + Simu_ano.values.tolist())

"""#PROPOSTAS CSOPS-TEMPLATE"""

calc_ano['Pagas no ano']=calc_ano.loc[(calc_ano['Status']=="DONE"),['Valor Total']]
calc_ano['Quantidade de Propostas']=calc_ano['Nome'].apply(lambda x: 1 if x!=1 else x)
calc_ano['Quantidade de Pagas']=calc_ano.loc[(calc_ano['Status']=="DONE"),['Quantidade de Propostas']]
calc_ano['Quantidade PAID']=calc_ano.loc[(calc_ano['Status']=="PAID"),['Quantidade de Propostas']]

cso=calc_ano[['Grupo','Valor Total','Pagas no ano','Quantidade de Propostas','Quantidade de Pagas','Quantidade PAID']]

cso['Quantidade de Propostas'].sum()

cso=cso.rename(columns={'Valor Total':'Valor de propostas'})

cso=cso.fillna(0)

cso=cso.groupby(['Grupo']).agg({'Quantidade de Propostas':'sum', 'Valor de propostas':'sum','Quantidade de Pagas':'sum','Pagas no ano':'sum','Quantidade PAID':'sum'}).reset_index()

cso['Grupo']=cso['Grupo'].str.upper()

cso=pd.merge(cso,ADE,how='left', on='Grupo')

cso=cso.fillna('')

paprica=prop_mes_sol.groupby(['Grupo']).agg({'Valor Total':'sum'}).reset_index()

paprica=paprica.rename(columns={'Valor Total':'Valor de todas as propostas Solicitadas'})

Analise_diaria=pd.merge(Analise_diaria,paprica,how='left',on='Grupo')

cso=cso[['Grupo','Quantidade de Propostas','Valor de propostas','Quantidade de Pagas','Pagas no ano','Modelo de Negócio','Quantidade PAID']]

Analise_diaria['Valor de todas as propostas Solicitadas']=Analise_diaria['Valor de todas as propostas Solicitadas'].fillna(0)

Analise_diaria

qppa=Dp.worksheet('Quantidade de Propostas/Pagas/Ano')
cell_list = qppa.range("A1:G5000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
qppa.update_cells(cell_list)
qppa.update([cso.columns.values.tolist()] + cso.values.tolist())
cell_list = sheet2.range("A1:O5000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
sheet2.update_cells(cell_list)
sheet2.update([Analise_diaria.columns.values.tolist()] + Analise_diaria.values.tolist())

"""#SIMULAÇÔES E PROPOSTAS ÙNICAS"""

unico_prop=pea.drop_duplicates(subset=['CPF NORMALIZADO'])
unico_simu=Simu_valor.drop_duplicates(subset=['cpf'])

unico_prop=unico_prop.query('`Mes da Solcitação`==@mes &`Ano da Solicitação`==@ano')
unico_prop=unico_prop[['Grupo','CPF NORMALIZADO','Valor Total']]
unico_prop['Propostas']=unico_prop['CPF NORMALIZADO'].apply(lambda x: 1)
unico_prop=unico_prop.groupby(['Grupo']).agg({'Propostas':'sum','Valor Total':'sum'}).reset_index()
unico_prop['Grupo']=unico_prop['Grupo'].str.upper()

unico_simu=unico_simu.query('Mes==@mes & Ano==@ano')
unico_simu=unico_simu[['value','paketa_groups → name','cpf']]
unico_simu['Simulações']=unico_simu['cpf'].apply(lambda x: 1)
unico_simu=unico_simu.groupby(['paketa_groups → name']).agg({'Simulações':'sum','value':'sum'}).reset_index()
unico_simu=unico_simu.rename(columns={'paketa_groups → name':'Grupo','value':'Valor Simulado'})
unico_simu['Grupo']=unico_simu['Grupo'].str.upper()

unico_prop_simu=pd.merge(unico_simu,unico_prop,how='outer')

unico_prop_simu=unico_prop_simu.fillna(0)

unico_prop_simu=unico_prop_simu.groupby(['Grupo']).agg({'Simulações':'sum','Valor Simulado':'sum','Propostas':'sum','Valor Total':'sum'}).reset_index()

unico_prop_simu=pd.merge(unico_prop_simu,ADE,how='left',on='Grupo')

unico_prop_simu['Modelo de Negócio']=unico_prop_simu['Modelo de Negócio'].fillna('SAAS')
unico_prop_simu['Status']=unico_prop_simu['Status'].fillna('ATIVO')

simu_prop_unique=Dp.worksheet('Simulações e Propostas por cpf único/MÊS')
cell_list =simu_prop_unique.range("A1:G5000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
simu_prop_unique.update_cells(cell_list)
simu_prop_unique.update([unico_prop_simu.columns.values.tolist()] + unico_prop_simu.values.tolist())

"""#Conversão para uso futuro"""

hist=pea[['Grupo','CPF NORMALIZADO','Valor Total','Ano da Solicitação','Modelo de negócio', 'Mes da Solcitação','Status','Ano do Pagamento','Mes do Pagamento']]

hist=hist.query('`Ano do Pagamento`==@ano | `Ano da Solicitação`==2022')

hist['Quantidade Solicitada']=hist['Status'].apply(lambda x: 1)

hist['Quantidade pagas']=hist['Status'].apply(lambda x: 1 if x=="DONE" else 0 )

hist

hist['Solicitadas Janeiro']=hist.loc[(hist['Mes da Solcitação']==1),['Quantidade Solicitada']]
hist['Solicitadas Fevereiro']=hist.loc[(hist['Mes da Solcitação']==2),['Quantidade Solicitada']]
hist['Solicitadas Março']=hist.loc[(hist['Mes da Solcitação']==3),['Quantidade Solicitada']]
hist['Solicitadas Abril']=hist.loc[(hist['Mes da Solcitação']==4),['Quantidade Solicitada']]
hist['Solicitadas Maio']=hist.loc[(hist['Mes da Solcitação']==5),['Quantidade Solicitada']]
hist['Solicitadas Junho']=hist.loc[(hist['Mes da Solcitação']==6),['Quantidade Solicitada']]
hist['Solicitadas Julho']=hist.loc[(hist['Mes da Solcitação']==7),['Quantidade Solicitada']]
hist['Solicitadas Agosto']=hist.loc[(hist['Mes da Solcitação']==8),['Quantidade Solicitada']]
hist['Solicitadas Setembro']=hist.loc[(hist['Mes da Solcitação']==9),['Quantidade Solicitada']]
hist['Solicitadas Outubro']=hist.loc[(hist['Mes da Solcitação']==10),['Quantidade Solicitada']]
hist['Solicitadas Novembro']=hist.loc[(hist['Mes da Solcitação']==11),['Quantidade Solicitada']]
hist['Solicitadas Dezembro']=hist.loc[(hist['Mes da Solcitação']==12),['Quantidade Solicitada']]

hist['Pagas Janeiro']=hist.loc[(hist['Mes do Pagamento']==1),['Quantidade pagas']]
hist['Pagas Fevereiro']=hist.loc[(hist['Mes do Pagamento']==2),['Quantidade pagas']]
hist['Pagas Março']=hist.loc[(hist['Mes do Pagamento']==3),['Quantidade pagas']]
hist['Pagas Abril']=hist.loc[(hist['Mes do Pagamento']==4),['Quantidade pagas']]
hist['Pagas Maio']=hist.loc[(hist['Mes do Pagamento']==5),['Quantidade pagas']]
hist['Pagas Junho']=hist.loc[(hist['Mes do Pagamento']==6),['Quantidade pagas']]
hist['Pagas Julho']=hist.loc[(hist['Mes do Pagamento']==7),['Quantidade pagas']]
hist['Pagas Agosto']=hist.loc[(hist['Mes do Pagamento']==8),['Quantidade pagas']]
hist['Pagas Setembro']=hist.loc[(hist['Mes do Pagamento']==9),['Quantidade pagas']]
hist['Pagas Outubro']=hist.loc[(hist['Mes do Pagamento']==10),['Quantidade pagas']]
hist['Pagas Novembro']=hist.loc[(hist['Mes do Pagamento']==11),['Quantidade pagas']]
hist['Pagas Dezembro']=hist.loc[(hist['Mes do Pagamento']==12),['Quantidade pagas']]

coversao=hist.groupby(['Grupo','Modelo de negócio']).sum().reset_index()

coversao.drop(['CPF NORMALIZADO','Valor Total','Ano da Solicitação','Mes da Solcitação','Ano do Pagamento','Mes do Pagamento'],axis=1, inplace=True)

cj= gc.open_by_url('https://docs.google.com/spreadsheets/d/1Jkj-WQIc47rg2_SGhANIOsivUVRn1Jy6VhdeRRNgcQA/edit#gid=2028797608')
Hj=cj.worksheet('Conversão Histórica')
Hj.update([coversao.columns.values.tolist()]+coversao.values.tolist())

reprovo=reprov3[['Grupo','Motivo Reprovação','Data/Horário Reprovação','Valor Total','CPF Tomador']]

reprovo['CPF Tomador']=reprovo['CPF Tomador'].apply(lambda x: 1)

reprovo['Data/Horário Reprovação']=pd.Series(reprovo['Data/Horário Reprovação'], dtype="string")

reprovo['Data/Horário Reprovação']=reprovo['Data/Horário Reprovação'].str.slice(0,10)

reprovo['Ano']=reprovo['Data/Horário Reprovação'].str.slice(0,4)

reprovo['Ano']=pd.to_numeric(reprovo['Ano'])

reprovo22=reprovo.query('Ano==@ano')

"""##Reprovo DOCS Growth"""

reprovo22['Mes']=reprovo22['Data/Horário Reprovação'].str.slice(5,7)

reprovo22['Mes']=pd.to_numeric(reprovo22['Mes'])

reprovo_mes=reprovo22.query('Mes==@mes | Mes==@mes1 | Mes==@mes2 | Mes==@mes3')

reprovo_mes_docs=reprovo_mes.query('`Motivo Reprovação`=="MISSING_CUSTOMER_FINAL_INFORMATIONS"')

reprovo_mes_atual=reprovo_mes_docs.query('Mes==@mes')

rpma=reprovo_mes_atual['Valor Total'].sum()

rpmaj=reprovo_mes_docs.query('Mes==@mes1')

rpmaj=rpmaj['Valor Total'].sum()

rpdt=reprovo_mes_docs['Valor Total'].sum().round()

rpdt=int(rpdt)
rpmaj=int(rpmaj)
rpma=int(rpma)

reprovo_mes_cred=reprovo_mes.query('`Motivo Reprovação`=="COMPANY_DOES_NOT_RELEASE_MORE_THAN_ONE_LOAN_PER_EMPLOYEE" |`Motivo Reprovação`=="CUSTOMER_DEBTS_NEGATIVES"|`Motivo Reprovação`=="INELIGIBLE_CUSTOMER_CPF_SUSPENDED" |`Motivo Reprovação`=="NO_CONSIGNABLE_MARGIN"')

reprovo_mes_cred_atual=reprovo_mes_cred.query('Mes==@mes')
rpmcatual=reprovo_mes_cred_atual['Valor Total'].sum().round(2)

reprovo_mes_anterior_cred=reprovo_mes_cred.query('Mes==@mes1')

rpmacred=reprovo_mes_anterior_cred['Valor Total'].sum()

rpmcatual

rpmctotal=reprovo_mes_cred['Valor Total'].sum().round(2)

# tpi=gc.open_by_url('https://docs.google.com/spreadsheets/d/1Cf-pYlgPL2HKqCk7dM8y83-SRal-SMMDIAqBFnFIha4/edit#gid=0')
# rpl=tpi.worksheet('Projeção Consignado')
# rpl.update('B9', f'{int(rpma)}')
# rpl.update('B10', f'{int(rpmaj)}')
# rpl.update('B11', f'{int(rpdt)}')
# rpl.update('B13', f'{int(rpmcatual)}')
# rpl.update('B14', f'{int(rpmacred)}')
# rpl.update('B15', f'{int(rpmctotal)}')

"""##Reprovados Documentos Cs Plano 2022"""

reprov_docs=reprovo22.query('`Motivo Reprovação`=="MISSING_CUSTOMER_FINAL_INFORMATIONS"')

reprov_docs=reprov_docs.groupby('Grupo').sum().reset_index()

reprov_docs.drop(['Ano'],axis=1,inplace=True)

reprovo_cred=reprovo22.query('`Motivo Reprovação`=="COMPANY_DOES_NOT_RELEASE_MORE_THAN_ONE_LOAN_PER_EMPLOYEE" |`Motivo Reprovação`=="CUSTOMER_DEBTS_NEGATIVES"|`Motivo Reprovação`=="INELIGIBLE_CUSTOMER_CPF_SUSPENDED" |`Motivo Reprovação`=="NO_CONSIGNABLE_MARGIN"')

reprovo_cred=reprovo_cred.groupby('Grupo').agg({'Valor Total':'sum','CPF Tomador':'sum'}).reset_index()

reprovo_cred=reprovo_cred.rename(columns={'Valor Total':'Valor rejeição por crédito', 'CPF Tomador':'Quantidade de rejeição por crédito'})

reprova_hist=pd.merge(reprovo_cred,reprov_docs,how='outer', on='Grupo')

reprova_hist=reprova_hist.fillna('')

reprova_hist=reprova_hist.rename(columns={'Valor Total':'Valor rejeitado por documento', 'CPF Tomador':'Quantidade rejeitado por documento'})

rh=cj.worksheet('Reprovação Histórica')
rh.update([reprova_hist.columns.values.tolist()]+reprova_hist.values.tolist())

"""#Averbação"""

averb=averb[['CNPJ','NomeNegocio','Grupo','CPF','Nome','Data da Solicitação','Valor Total','Status','Dispensar Averbação']]

averb['Data']=pd.to_datetime(averb['Data da Solicitação'],format='%d/%m/%Y')

aver=averb[['CNPJ','NomeNegocio','Grupo','CPF','Nome','Valor Total','Status','Data','Dispensar Averbação']]

data_agora=datetime.datetime.today()

aver['Dias sem averbação']=aver['Data'].apply(lambda x: (data_agora-x).days)

aver=aver.query('`Dias sem averbação`<=7 & `Dispensar Averbação`=="Não"')

aver=aver.query('Status!="REJECTED_PAKETA" & Status!="REJECTED_RH" & Status!="DONE" & Status!="CANCELED" ')

aver=aver.query('`Dias sem averbação`>=3')

aver['Data']=pd.Series(aver['Data'],dtype="string")

aver=aver.fillna('')

aver_planilha=gc.open_by_url('https://docs.google.com/spreadsheets/d/1ZvUG9TB9YTpghMow0PcJIM9C65eywtr60tYlbMVGxQI/edit#gid=2050809209')
aver_work=aver_planilha.worksheet('Averbações')
aver_work.update([aver.columns.values.tolist()]+aver.values.tolist())

"""#VERZANI E SANDRINI

"""

#NomeNegocio	Nome	CPF	Valor Total	Status	Data da Solicitação	Data de Pagamento	Taxa (%)	Nº de parcelas	CNPJ

verzi_prop['Grupo']=verzi_prop['Grupo'].str.upper()

cnpjs=[7416434000116,28307919000141,78570397000659,57559387001703,57559387001614,57559387001029,57559387001100,
       57559387001290,57559387000308,57559387002009,57559387001452,57559387000995,57559387001967,57559387001533,
       57559387000480,57559387001886,78570397000578,
       6350648000174,29920000132,4130128000120,2125806000131,
       8634282000190,1016459000146,8979535000168,28331011000173,57559387000138,
       7774050000175,78570397000144,8347366000143,5473352000188,16627705000173,
       20938292000115,64179724000127,11092610000189]

# def listaFiltro(dataframe, valores):
#     return dataframe.loc[dataframe['CNPJ'].isin(valores)]
# dfteste = listaFiltro(verzi_prop, cnpjs)
# dfteste

Meses_tst={1:'jan.', 2:'fev.', 3:'mar.', 4:'abr.', 5:'mai.', 6:'jun.', 7:'jul.',8:'ago.', 9:'set.', 10:'out.', 11:'nov', 12:'dez'}

verzi_prop=verzi_prop.query('Grupo=="VERZANI & SANDRINI S.A." | Grupo=="FORT KNOX"')

verzi_penetração=pd.merge(verzi_prop,funcionarios_cancelados, how='left', on='CPF')

verzi_penetração['E-mail']=verzi_penetração['E-mail'].fillna('')

verzi_penetração.drop(verzi_penetração.loc[verzi_penetração['E-mail']==''].index, inplace=True)

verzi_penetração['CPF']=verzi_penetração['CPF'].apply(lambda x: 1)

verzi_penetração=verzi_penetração.groupby(['NomeNegocio']).agg({'CPF':'sum'}).reset_index()
verzi_penetração=verzi_penetração.sort_values(by=['CPF'], ascending=True)

verzani_base=verzi_prop

verzani_base['CPF']=verzani_base['CPF'].apply(lambda x: 1)

verzani_base['Semana da Solicitação']=pd.to_datetime(verzani_base['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%U"))

verzani_base['Mes da Solicitação']=pd.to_datetime(verzani_base['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m"))

verzani_base['Mes da Solicitação']=pd.to_numeric(verzani_base['Mes da Solicitação'])

verzani_base['Mes da Solicitação']=verzani_base['Mes da Solicitação'].apply(lambda x:Meses_tst.get(x))

verzani_base['Semana da Solicitação']=verzani_base['Semana da Solicitação']+'/'+verzani_base['Mes da Solicitação']

verzani_base['Ano da Solicitação']=pd.to_datetime(verzani_base['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%y"))

verzani_base['Mes da Solicitação']=verzani_base['Mes da Solicitação']+'/'+verzani_base['Ano da Solicitação']

verzani_base=verzani_base.rename(columns={'CPF':'Quantidade de Propostas'})

verzani_base['Quantidade Propostas Pagas']=verzani_base.loc[(verzani_base['Status'].apply(lambda x: 1 if x=="DONE" or x=="PAID" else x)==1),'Quantidade de Propostas']
verzani_base['Propostas Pagas']=verzani_base.loc[(verzani_base['Status'].apply(lambda x: 1 if x=="DONE" or x=="PAID" else x)==1),'Valor Total']
verzani_base['Propostas em análise']=verzani_base.loc[(verzani_base['Status'].apply(where)==1),'Valor Total']

verzani_base['Mes do Pagamento']=pd.to_datetime(verzani_base['Data de Pagamento'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m") if not pd.isnull(x) else '')

verzani_base['Mes do Pagamento']=pd.to_numeric(verzani_base['Mes do Pagamento'])

verzani_base['Ano do Pagamento']=pd.to_datetime(verzani_base['Data de Pagamento'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%y") if not pd.isnull(x) else '')

verzani_base=verzani_base.fillna('')

verzani_base['Mes do Pagamento']=verzani_base['Mes do Pagamento'].apply(lambda x: Meses_tst.get(x) if x!='' else x)

verzani_base['Mes do Pagamento']=verzani_base['Mes do Pagamento']+'/'+verzani_base['Ano do Pagamento']

verzani_base['Mes do Pagamento']=verzani_base['Mes do Pagamento'].apply(lambda x: "" if x=="/" else x)

verzani_base['Mes']=pd.to_datetime(verzani_base['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m"))

verzani_base['Mes']=pd.to_numeric(verzani_base['Mes'])

verzani_base=verzani_base.sort_values(by=['Ano da Solicitação',"Mes"], ascending=True)

verzani_base.drop(['Ano da Solicitação','Ano do Pagamento','Mes'],axis=1,inplace=True)

verzani_base=verzani_base[['NomeNegocio',	'Nome','Quantidade de Propostas',	'Valor Total',	'Status',	'Data da Solicitação',	'Data de Pagamento',	'Taxa (%)',	'Nº de parcelas',	'CNPJ',	'Grupo',	'Semana da Solicitação',	'Mes da Solicitação',	'Quantidade Propostas Pagas',	'Propostas Pagas','Mes do Pagamento','Propostas em análise']]

verzi_novas=verzi_prop.query('Grupo=="FORT KNOX" | NomeNegocio=="ISO CLEAN" | NomeNegocio=="ETICA CONSERVACAO & HIGIENIZACAO" | NomeNegocio=="ABILITY"')

verzi_novas['Mes']=pd.to_datetime(verzi_novas['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m"))
verzi_novas['Mes']=pd.to_numeric(verzi_novas['Mes'])
verzi_novas=verzi_novas.sort_values(by=['Ano da Solicitação',"Mes"], ascending=True)

#verzi_novas['FORT KNOX']=verzi_novas.loc[(verzi_novas['Grupo']=="FORT KNOX"),'CPF']
verzi_novas['ISO CLEAN']=verzi_novas.loc[(verzi_novas['NomeNegocio']=="ISO CLEAN"),'CPF']
verzi_novas['ETICA CONSERVACAO & HIGIENIZACAO']=verzi_novas.loc[(verzi_novas['NomeNegocio']=="ETICA CONSERVACAO & HIGIENIZACAO"),'CPF']
verzi_novas['ABILITY']=verzi_novas.loc[(verzi_novas['NomeNegocio']=="ABILITY"),'CPF']

verzi_novas=verzi_novas.groupby(['Mes da Solicitação','Ano da Solicitação','Mes']).agg({'ISO CLEAN':'sum','ETICA CONSERVACAO & HIGIENIZACAO':'sum',	'ABILITY':'sum'}).reset_index()
#'FORT KNOX':'sum',

verzi_novas=verzi_novas.sort_values(by=['Ano da Solicitação',"Mes"], ascending=True)

verzi_novas.drop(['Ano da Solicitação','Mes'], axis=1,inplace=True)

verzi_novas=verzi_novas.replace(0,"")

vsimulacoes=SIMULAÇÕES.query('Grupo=="VERZANI & SANDRINI S.A." | Grupo=="FORT KNOX"')

vsimulacoes['CPF']=vsimulacoes['CPF'].apply(lambda x: 1)

vsimulacoes['Mes da Simulaçao']=pd.to_datetime(vsimulacoes['Data'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m") if not pd.isnull(x) else '')
vsimulacoes['Ano da Simulaçao']=pd.to_datetime(vsimulacoes['Data'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%y") if not pd.isnull(x) else '')

vsimulacoes['Mes da Simulaçao']=pd.to_numeric(vsimulacoes['Mes da Simulaçao'])

vsimulacoes['Mes']=vsimulacoes['Mes da Simulaçao']

vsimulacoes['Mes da Simulaçao']=vsimulacoes['Mes da Simulaçao'].apply(lambda x:Meses_tst.get(x))

vsimulacoes['Mes da Simulaçao']=vsimulacoes['Mes da Simulaçao']+'/'+vsimulacoes['Ano da Simulaçao']

vsimulacoes=vsimulacoes.groupby(['Empresa','Grupo','Mes da Simulaçao','Mes','Ano da Simulaçao']).agg({'CPF':'sum'}).reset_index()

vsimulacoes=vsimulacoes.sort_values(by=['Ano da Simulaçao',"Mes"], ascending=False)

vsimulacoes.drop(['Mes','Ano da Simulaçao'], axis=1, inplace=True)

verzani_base['Propostas Pagas']=pd.to_numeric(verzani_base['Propostas Pagas'])
verzani_base['Propostas em análise']=pd.to_numeric(verzani_base['Propostas em análise'])

verzani_empresas=verzani_base.groupby(['NomeNegocio']).agg({'Propostas Pagas':'sum','Propostas em análise':'sum'}).reset_index()

verzani_base=verzani_base.fillna('')

verzani_empresas=verzani_empresas.sort_values(by=['Propostas Pagas'], ascending=False)

verzani_novo_planilha=gc.open_by_url('https://docs.google.com/spreadsheets/d/1TnNgnnuFVEorQM7cUUUHF316u68GDngl6tq9qRk-DZc/edit#gid=0')
verzani_novo=verzani_novo_planilha.worksheet('Propostas')
verzani_novo.update([verzani_base.columns.values.tolist()]+verzani_base.values.tolist())

verzani_empresas_plan=verzani_novo_planilha.worksheet('Pagos por empresa')
verzani_empresas_plan.update([verzani_empresas.columns.values.tolist()]+verzani_empresas.values.tolist())

verzi_novas_empresas=verzani_novo_planilha.worksheet('Novas empresas Produção')
verzi_novas_empresas.update([verzi_novas.columns.values.tolist()]+verzi_novas.values.tolist())

vsimu=verzani_novo_planilha.worksheet('SIMULAÇÕES')
vsimu.update([vsimulacoes.columns.values.tolist()]+vsimulacoes.values.tolist())

verzi_func_ativos=verzani_novo_planilha.worksheet('EMPRESTIMOS DE FUNCIONARIOS AINDA ATIVOS')
verzi_func_ativos.update([verzi_penetração.columns.values.tolist()]+verzi_penetração.values.tolist())

"""#Visão mes anterior No mesmo dias de propostas"""

visao=pea[['Grupo', 'CPF NORMALIZADO','Valor Total','Status','Ano da Solicitação','Mes da Solcitação','Ano do Pagamento','Mes do Pagamento','Data da Solicitação','Data de Pagamento']]

visao['Dia util solicitação']=pd.to_datetime(visao['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: x.weekday())

visao['Dia util pagamento']=pd.to_datetime(visao['Data de Pagamento'],format="%d/%m/%Y").apply(lambda x: x.weekday() if not pd.isnull(x) else '')

visao['Dia da Solicitação']=visao['Data da Solicitação'].str.slice(0,2)
visao['Dia do Pagamento']=visao['Data de Pagamento'].str.slice(0,2)

visao['Dia da Solicitação']=pd.to_numeric(visao['Dia da Solicitação'])
visao['Dia do Pagamento']=pd.to_numeric(visao['Dia do Pagamento'])

visao=visao.query('`Ano da Solicitação`==@ano|`Ano do Pagamento`==@ano')

visao['CPF NORMALIZADO']=visao['CPF NORMALIZADO'].apply(lambda x: 1)
visao=visao.rename(columns={'CPF NORMALIZADO':'Propostas'})
visao['Propostas']=pd.to_numeric(visao['Propostas'])

visao['Propostas Pagas']=visao.loc[(visao['Status']=="DONE"),'Propostas']

visao['PAID']=visao.loc[(visao['Status']=="PAID"),'Propostas']

visao['Propostas Pagas']=visao['Propostas Pagas'].fillna(0)+visao['PAID'].fillna(0)

visao['Proposta pagas mes atual']=visao.loc[(visao['Mes do Pagamento']==mes),'Propostas Pagas']
visao['Proposta pagas mes passado']=visao.loc[(visao['Mes do Pagamento']==mes1),'Propostas Pagas']

visao_x=visao.groupby(['Grupo','Mes da Solcitação','Dia da Solicitação',]).agg({'Propostas':'sum'}).reset_index()

# visao_total['Proposta pagas mes passado']=visao_total.loc[(visao_total['Mes do Pagamento']==mes1),'Propostas pagas']

visao_pec=visao.groupby(['Grupo','Dia do Pagamento','Mes do Pagamento']).agg({'Propostas Pagas':'sum'}).reset_index()

visao_soli=pd.concat([visao_x,visao_pec])

# # visao_total['Proposta mes atual']=visao_total.loc[(visao_total['Mes da Solcitação']==mes),'Propostas']
# visao_total['Proposta mes passado']=visao_total.loc[(visao_total['Mes da Solcitação']==mes1),'Propostas']
# visao_total['Proposta pagas mes atual']=visao_total.loc[(visao_total['Mes do Pagamento']==mes),'Propostas pagas']
# visao_total['Proposta pagas mes passado']=visao_total.loc[(visao_total['Mes do Pagamento']==mes1),'Propostas pagas']

# visao_total=visao_total[['Grupo','Proposta mes atual'	,'Proposta mes passado'	,'Proposta pagas mes atual'	,'Proposta pagas mes passado','Dia da Solicitação']]

visao_soli=visao_soli.query('`Mes do Pagamento`>=@mes3|`Mes da Solcitação`>=@mes3')

visao_mes=visao_soli[['Grupo','Mes da Solcitação','Propostas','Mes do Pagamento','Propostas Pagas']]

visao_soli=visao_soli.query('`Dia da Solicitação`<=@dia | `Dia do Pagamento`<=@dia')

dia

visao_soli['Mes da Solcitação']=visao_soli['Mes da Solcitação'].fillna('')
visao_soli['Dia da Solicitação']=visao_soli['Dia da Solicitação'].fillna('')
visao_soli['Dia do Pagamento']=visao_soli['Dia do Pagamento'].fillna('')
visao_soli['Mes do Pagamento']=visao_soli['Mes do Pagamento'].fillna('')
visao_soli['Propostas']=visao_soli['Propostas'].fillna(0)
visao_soli['Propostas Pagas']=visao_soli['Propostas Pagas'].fillna(0)

vi_sol=Dp.worksheet('COMPARATIVO MÊS A MÊS/DADOS BRUTOS')
cell_list = vi_sol.range("A1:G10000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
vi_sol.update_cells(cell_list)
vi_sol.update([visao_soli.columns.values.tolist()]+visao_soli.values.tolist())



"""#Visão comparativa de simulações mesmo dia"""

Simu_valor['dia']=pd.to_numeric(Simu_valor['dia'])

visao_comp_mes=Simu_valor.query('Ano==@ano')

visao_comp_mes=visao_comp_mes.query('Mes==@mes | Mes==@mes1 | Mes==@mes2 | Mes==@mes3')

visao_comp_mes['cpf']=visao_comp_mes['cpf'].apply(lambda x: 1)

visao_simu=visao_comp_mes.groupby(['paketa_groups → name','dia','Mes']).agg({'cpf':'sum','value':'sum'}).reset_index()

visao_simu.drop(visao_simu.loc[visao_simu['paketa_groups → name']==''].index, inplace=True)

visao_simu=visao_simu.rename(columns={'paketa_groups → name':'Grupo','cpf':'Quantidade','value':'Valor','dia':'Dia'})

visao_simux=visao_simu[['Grupo','Mes','Quantidade','Valor']]

visao_soli_prop=pd.concat([visao_simux,visao_mes])

visao_soli_prop['Mes']=visao_soli_prop['Mes'].fillna('')
visao_soli_prop['Mes da Solcitação']=visao_soli_prop['Mes da Solcitação'].fillna('')
visao_soli_prop['Mes do Pagamento']=visao_soli_prop['Mes do Pagamento'].fillna('')
visao_soli_prop=visao_soli_prop.fillna(0)

visao_simu=visao_simu.query('Dia<=@dia')

visao_simulacao=Dp.worksheet('COMPARATIVO MÊS A MÊS SIMULAÇÕES')
visao_simulacao_propostas=Dp.worksheet('SIMULAÇÕES E PROPOSTAS 3 ÚLTIMOS MESES')
cell_list = visao_simulacao.range("A1:E12000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
visao_simulacao.update_cells(cell_list)
visao_simulacao.update([visao_simu.columns.values.tolist()]+visao_simu.values.tolist())
cell_list = visao_simulacao_propostas.range("A1:H15000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
visao_simulacao_propostas.update_cells(cell_list)
visao_simulacao_propostas.update([visao_soli_prop.columns.values.tolist()]+visao_soli_prop.values.tolist())

"""#Propostas em aberto no Cockpit"""

cokipit_abertos['Mes da Solcitação']=pd.to_datetime(cokipit_abertos['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%m") if not pd.isnull(x) else '')

cokipit_abertos['Ano da Solicitação']=pd.to_datetime(cokipit_abertos['Data da Solicitação'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%Y") if not pd.isnull(x) else '')

cokipit_abertos['Ano da Solicitação']=pd.Series(cokipit_abertos['Ano da Solicitação'], dtype="int64")
cokipit_abertos['Mes da Solcitação']=pd.Series(cokipit_abertos['Mes da Solcitação'], dtype="int64")

abertos_cockipit=cokipit_abertos.query('Status=="IN_ANALYSIS_PAKETA"')

abertos_cockipit=abertos_cockipit.query('`Ano da Solicitação`==@ano')

abertos_cockipit=abertos_cockipit[['NomeNegocio','Nome','CPF','Valor Total','Data da Solicitação','Grupo','Nº de parcelas','Taxa (%)']]

abertos_cockipit=abertos_cockipit.fillna('')

cockipit_planilha=gc.open_by_url('https://docs.google.com/spreadsheets/d/1e0ojH51dZll7ZSRKBnWy1NJAnHc7E3hUOU73Vf9bWJM/edit#gid=0')
cokipit=cockipit_planilha.worksheet('Propostas em aberto no cockpit')
cokipit.clear()
cokipit.update([abertos_cockipit.columns.values.tolist()]+abertos_cockipit.values.tolist())

"""#ANÁLISE DAS CONTAS POR CNPJS"""

soma_nome=pea

soma_nome['CPF NORMALIZADO']=soma_nome['CPF NORMALIZADO'].apply(lambda x: 1)
soma_nome=soma_nome.rename(columns={'CPF NORMALIZADO':'Propostas'})
soma_nome['Propostas pagas']=soma_nome.loc[(soma_nome['Status']=='DONE'),'Propostas']
soma_nome['Propostas pagas R$']=soma_nome.loc[(soma_nome['Status']=='DONE'),'Valor Total']

soma_nomenegocio=soma_nome.groupby(['NomeNegocio','CNPJ','Grupo','Ano da Solicitação','Mes da Solcitação',	'Ano do Pagamento',	'Mes do Pagamento']).agg({'Propostas':'sum','Valor Total':'sum','Propostas pagas':'sum','Propostas pagas R$':'sum'}).reset_index()

nome_negocio_soma=Dp.worksheet('ANÁLISE DAS CONTAS POR CNPJ')
nome_negocio_soma.update([soma_nomenegocio.columns.values.tolist()]+soma_nomenegocio.values.tolist())



"""#Cancelados"""

cancelados_cokipit=cokipit_abertos.query('Status=="CANCELED"')

cancelados_cokipit=cancelados_cokipit.query('`Mes da Solcitação`==@mes & `Ano da Solicitação`==@ano')

cancelados_cokipit=cancelados_cokipit[['CPF','Nome','NomeNegocio','Valor Total','Grupo']]
#CPF, Nome, email, telefone, nome do grupo, valor do empréstimo

elegiveis_cancelados=funcionarios_cancelados[['CPF','Telefone','E-mail']]

cancelados_merge=pd.merge(cancelados_cokipit,elegiveis_cancelados,how='left', on="CPF")

cancelados_merge=cancelados_merge.fillna('')

cancelados_merge=cancelados_merge.query('Grupo!="GRUPO GR"')

cancelados_merge['Grupo']=cancelados_merge['Grupo'].str.upper()

cancelados_merge=pd.merge(cancelados_merge,ADE, how='left', on='Grupo')

cancelados_merge=cancelados_merge.query('`Modelo de Negócio`!="SaaS"')

cancelados_merge=cancelados_merge.query('Grupo!="HAGANÁ"')

cancelados_merge=cancelados_merge[['CPF'	,'Nome'	,'NomeNegocio'	,'Valor Total'	,'Grupo'	,'Telefone'	,'E-mail']]

canceled_prop=gc.open_by_url('https://docs.google.com/spreadsheets/d/1PFsMLnjTQ65Eum4gxv2Gi-klUdIozbtOXa2-Evr1E0Q/edit#gid=0')
canceled_new=canceled_prop.worksheet('PROPOSTAS CANCELADAS')
canceled_new.clear()

canceled_new.update([cancelados_merge.columns.values.tolist()]+cancelados_merge.values.tolist())

reprov_desistencia=Reprovação.query('Traduzido=="O CLIENTE DESISTIU DA PROPOSTA"')

reprov_desistencia=reprov_desistencia.query('Grupo!="GRUPO GR"')
reprov_desistencia=reprov_desistencia.query('`Modelo de Negócio`!="SaaS"')
reprov_desistencia=reprov_desistencia.query('Grupo!="SUPERMARKET ALVORADA"')

reprov_desistencia=reprov_desistencia[['Grupo','Traduzido','Status','Comentário Reprovação','Tomador','CPF Tomador']]

reprov_cli_des_prop=canceled_prop.worksheet('REPROVAÇÕES')
reprov_cli_des_prop.clear()
reprov_cli_des_prop.update([reprov_desistencia.columns.values.tolist()]+reprov_desistencia.values.tolist())



"""#SOLICITAÇÕES E PAGAMENTOS DIA ÚTIL

"""

ADE=ADE[['Grupo','Modelo de Negócio']]

DIAS = {0:'Segunda-feira',1:'Terça-feira',2:'Quarta-feira',3:'Quinta-Feira',4:'Sexta-feira',5:'Sábado',6:'Domingo'}
visao['Grupo']=visao['Grupo'].str.upper()
visao=pd.merge(visao,ADE,how='left',on='Grupo')

visao_s=visao.groupby(['Modelo de Negócio','Mes da Solcitação','Dia util solicitação','Dia da Solicitação']).agg({'Propostas':'sum'}).reset_index()

visao_s=visao_s.query('`Dia util solicitação`<=4')
visao_s=visao_s.query('`Dia da Solicitação`<=@dia')

visao_s['Dia util solicitação']=visao_s['Dia util solicitação'].apply(lambda x: DIAS.get(x))

visao_s=visao_s.query('`Mes da Solcitação`>=@mes1')

visao_p=visao.groupby(['Modelo de Negócio','Mes do Pagamento','Dia do Pagamento','Dia util pagamento']).agg({'Propostas Pagas':'sum'}).reset_index()

visao_p=visao_p.query('`Dia util pagamento`<=4')
visao_p=visao_p.query('`Dia do Pagamento`<=@dia')

visao_p['Dia util pagamento']=visao_p['Dia util pagamento'].apply(lambda x: DIAS.get(x))

visao_p=visao_p.query('`Mes do Pagamento`>=@mes1')

visao_p[f'Pagas {Meses.get(mes)}']=visao_p.loc[(visao_p['Mes do Pagamento']==mes),'Propostas Pagas']

visao_p[f'Pagas {Meses.get(mes1)}']=visao_p.loc[(visao_p['Mes do Pagamento']==mes1),'Propostas Pagas']

visao_p=visao_p.groupby(['Modelo de Negócio','Dia do Pagamento','Dia util pagamento']).agg({f'Pagas {Meses.get(mes)}':'sum',f'Pagas {Meses.get(mes1)}':'sum'}).reset_index()

visao_s[Meses.get(mes)]=visao_s.loc[(visao_s['Mes da Solcitação']==mes),'Propostas']
visao_s[Meses.get(mes1)]=visao_s.loc[(visao_s['Mes da Solcitação']==mes1),'Propostas']

visao_s=visao_s.groupby(['Modelo de Negócio','Dia util solicitação','Dia da Solicitação']).agg({Meses.get(mes):'sum',Meses.get(mes1):'sum'}).reset_index()

visao_s=visao_s.rename(columns={'Dia da Solicitação':'Dia da Proposta'})
visao_p=visao_p.rename(columns={'Dia do Pagamento':'Dia da Proposta'})

visao_s_p=pd.concat([visao_p,visao_s])

visao_s_p.sum()

visao_s_p=visao_s_p.groupby(['Dia da Proposta','Modelo de Negócio']).agg({Meses.get(mes):'sum',Meses.get(mes1):'sum',f'Pagas {Meses.get(mes)}':'sum',f'Pagas {Meses.get(mes1)}':'sum'}).reset_index()

simu_soli=Simu_valor.query('Mes>=@mes1')
simu_soli=simu_soli.query('dia<=@dia')

simu_soli['Dia util simulações']=pd.to_datetime(simu_soli['updatedAt'],format="%Y-%m-%d").apply(lambda x: x.weekday())

simu_soli['cpf']=simu_soli['cpf'].apply(lambda x: 1)

simu_soli=simu_soli.query('`Dia util simulações`<=4')

simu_soli=simu_soli.rename(columns={'cpf':'Simulações','paketa_groups → name':'Grupo','dia':'Dia da Proposta'})

simu_soli['Grupo']=simu_soli['Grupo'].str.upper()

simu_soli[f'Simulações {Meses.get(mes1)}']=simu_soli.loc[(simu_soli['Mes']==mes1),'Simulações']
simu_soli[f'Simulações {Meses.get(mes)}']=simu_soli.loc[(simu_soli['Mes']==mes),'Simulações']

simu_soli=simu_soli.groupby(['Grupo','Dia da Proposta']).agg({f'Simulações {Meses.get(mes)}':'sum',f'Simulações {Meses.get(mes1)}':'sum'}).reset_index()

simu_soli=pd.merge(simu_soli,ADE,how='left', on='Grupo')

simu_soli=simu_soli.groupby(['Dia da Proposta','Modelo de Negócio']).agg({f'Simulações {Meses.get(mes)}':'sum',f'Simulações {Meses.get(mes1)}':'sum'}).reset_index()

visao_soli_pagas=gc.open_by_url('https://docs.google.com/spreadsheets/d/1uUeeRe78OIAlfqNt6sL0DDR3sema8DAHTVJRwE5s-lM/edit#gid=1918701766')
visao_soli_pagas_planilha=visao_soli_pagas.worksheet('PROPOSTAS')
visao_soli_pagas_planilha.clear()
visao_soli_pagas_planilha.update([visao_s_p.columns.values.tolist()]+visao_s_p.values.tolist())
visao_simu_soli=visao_soli_pagas.worksheet('SIMULAÇÕES')
visao_simu_soli.clear()
visao_simu_soli.update([simu_soli.columns.values.tolist()]+simu_soli.values.tolist())

SIMULAÇÕES['Grupo']=SIMULAÇÕES['Grupo'].str.upper()
MAIS_TODOS=SIMULAÇÕES.query('Grupo=="MAISTODOS"')

MAIS_TODOS=MAIS_TODOS.drop_duplicates(subset=['CPF'])

MAIS_TODOS['Data']=pd.to_datetime(MAIS_TODOS['Data'],format="%d/%m/%Y").apply(lambda x: datetime.datetime.strftime(x, "%d"))

MAIS_TODOS['Data']=pd.to_numeric(MAIS_TODOS['Data'])

MAIS_TODOS=MAIS_TODOS.query('Data==@dia')

ckipit_mais_todos=cockipit_planilha.worksheet('SIMULAÇÕES SEM EMPRESTIMO')
ckipit_mais_todos.clear()

ckipit_mais_todos.update([MAIS_TODOS.columns.values.tolist()]+MAIS_TODOS.values.tolist())

"""#RRANGE DE GRUPOS-MIN E MAX"""

range_minmax['Grupo']=range_minmax['Grupo'].str.upper()
range_mini_maxi=range_minmax.query('Grupo=="GRUPO PLURIS" |Grupo=="GRUPO PLURIS-DEMAIS EMPRESAS"|Grupo=="HIPERSTREAM"|Grupo=="INFOX"|Grupo=="INVILLIA"|Grupo=="REMESSA ON LINE"|Grupo=="RICCÓ"|Grupo=="T-SYSTEMS"')

#mean_df=tempod['Dias entre solicitação e pagamento'].describe()

range_mini_maxi=range_mini_maxi.groupby(['Grupo']).agg({'Taxa (%)':'describe'}).reset_index()

range_test=range_minmax.groupby(['Grupo']).agg({'Valor Total':'describe'}).reset_index()

"""#RD STATION"""

caminho10='/content/drive/Othercomputers/Meu laptop/Leads_ RD STATION CS SALES'
lista_arquivos10= os.listdir(caminho10)
lista_datas10= []
for arquivo in lista_arquivos10:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho10}/{arquivo}")
  lista_datas10.append((data, arquivo))

lista_datas10.sort(reverse=True)
ultimo_arquivo10= lista_datas10[0]
arquivo10=ultimo_arquivo10[1]

RD=pd.read_csv(f"{caminho10}/{arquivo10}")

RD=pd.DataFrame(RD).reset_index()

caminho10='/content/drive/Othercomputers/Meu laptop/FGTS RD'
lista_arquivos10= os.listdir(caminho10)
lista_datas10= []
for arquivo in lista_arquivos10:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho10}/{arquivo}")
  lista_datas10.append((data, arquivo))

lista_datas10.sort(reverse=True)
ultimo_arquivo10= lista_datas10[0]
arquivo10=ultimo_arquivo10[1]

RD_FGT=pd.read_csv(f"{caminho10}/{arquivo10}")

RD2 = RD.rename(columns=RD.iloc[0]).loc[1:]

RD_FGTS=RD_FGT[['Nome do Usuário','Pagas']]

RD2['Valor Único']=pd.to_numeric(RD2['Valor Único'])
RD2['Valor Recorrente']=pd.to_numeric(RD2['Valor Recorrente'])

RD2=RD2.query('`Valor Único`!=0')

RD2['Data de fechamento']=RD2['Data de fechamento'].str.slice(3,)

RD_FGTS['Nome do Usuário']=RD_FGTS['Nome do Usuário'].str.upper()

RD_FGTS['Pagas']=RD_FGTS['Pagas'].str.slice(3,)

RD_FGTS['Pagas']=pd.to_numeric(RD_FGTS['Pagas'])

RD2['Responsável']=RD2['Responsável'].str.upper()

rd_chey=RD2.query('Responsável=="CHEYENNE ALBUQUERQUE" & `Data de fechamento`==@data_atual & Estado=="Vendida"')
rd_fernanda=RD2.query('Responsável=="FERNANDA MENDES PACHELI" & `Data de fechamento`==@data_atual & Estado=="Vendida"')
rd_flavia_oliveira=RD2.query('Responsável=="FLAVIA OLIVEIRA" & `Data de fechamento`==@data_atual & Estado=="Vendida"')
rd_flavia_guedes=RD2.query('Responsável=="FLÁVIA GUEDES" & `Data de fechamento`==@data_atual & Estado=="Vendida"')

rd_cheyfgts=RD_FGTS.query('`Nome do Usuário`=="CHEYENNE DIAS LIMAS ALBUQUERQUE"')
rd_fernandafgts=RD_FGTS.query('`Nome do Usuário`=="FERNANDA MENDES PACHELI"')
rd_flavia_oliveirafgts=RD_FGTS.query('`Nome do Usuário`=="FLÁVIA APOLINÁRIA DE OLIVEIRA SILVA"')
rd_flavia_guedesfgts=RD_FGTS.query('`Nome do Usuário`=="FLÁVIA REGINA DA SILVA GUEDES"')

rd_cheyfgts=rd_cheyfgts['Pagas'].sum()
rd_fernandafgts=rd_fernandafgts['Pagas'].sum()
rd_flavia_oliveirafgts=rd_flavia_oliveirafgts['Pagas'].sum()
rd_flavia_guedesfgts=rd_flavia_guedesfgts['Pagas'].sum()
rd_flavia_guedesfgts=0

rd_chey=rd_chey['Valor Único'].sum()
rd_fernanda=rd_fernanda['Valor Único'].sum()
rd_flavia_oliveira=rd_flavia_oliveira['Valor Único'].sum()
rd_flavia_guedes=rd_flavia_guedes['Valor Único'].sum()

rd_chey

rd_chey=rd_chey+rd_cheyfgts
rd_fernanda=rd_fernanda+rd_fernandafgts
rd_flavia_oliveira=rd_flavia_oliveira+rd_flavia_oliveirafgts
rd_flavia_guedes=rd_flavia_guedes+rd_flavia_guedesfgts

rd_cheyfgts

meta_rd=750000
meta_flavias=600000

rd_chey_dp=rd_chey/meta_rd
rd_fernanda_dp=rd_fernanda/meta_rd
rd_flavia_oliveira_dp=rd_flavia_oliveira/meta_flavias
rd_flavia_guedes_dp=rd_flavia_guedes/meta_flavias

previ_chey=rd_chey/Dias_uteis_hoje
previ_chey=previ_chey*Dias_uteis
previ_fernanda=rd_fernanda/Dias_uteis_hoje
previ_fernanda=previ_fernanda*Dias_uteis
previ_fl_oli=rd_flavia_oliveira/Dias_uteis_hoje
previ_fl_oli=previ_fl_oli*Dias_uteis
previ_fl_gue=rd_flavia_guedes/Dias_uteis_hoje
previ_fl_gue=previ_fl_gue*Dias_uteis

chey='\U0001F469'
fernanda_pch='\U0001F471'
flavia_oli='\U0001F467'
flavia_guedes='\U0001F470'

dici_rd= {
    'Meta': pd.Series([600000, 600000, 300000, 300000], index=['Cheyenne', 'Fernanda', 'Flavia Oliveira', 'Flavia Guedes']),
    'Produzido': pd.Series([rd_chey, rd_fernanda, rd_flavia_oliveira, rd_flavia_guedes], index=['Cheyenne', 'Fernanda', 'Flavia Oliveira', 'Flavia Guedes']),
    'Desempenho': pd.Series([rd_chey_dp,rd_fernanda_dp , rd_flavia_oliveira_dp, rd_flavia_guedes_dp], index=['Cheyenne', 'Fernanda', 'Flavia Oliveira', 'Flavia Guedes']),
    'Previsão' : pd.Series([previ_chey, previ_fernanda, previ_fl_oli, previ_fl_gue], index=['Cheyenne', 'Fernanda', 'Flavia Oliveira', 'Flavia Guedes'])
    
    
}

# Criando dataframe
df_rd= pd.DataFrame(dici_rd)

rd_lista=[rd_chey,rd_fernanda,rd_flavia_oliveira,rd_flavia_guedes,meta_rd,rd_chey_dp,rd_fernanda_dp,rd_flavia_oliveira_dp,rd_flavia_guedes_dp,previ_chey,previ_fernanda,previ_fl_oli,previ_fl_gue,meta_flavias]

for i in range(len(rd_lista)):
  if rd_lista[i]>=1000 and rd_lista[i]<1000000:
      rd_lista[i]=rd_lista[i]/1000
      rd_lista[i]=round(rd_lista[i])
      rd_lista[i]=str(rd_lista[i])+" K"
  elif rd_lista[i]>=1000000:
      rd_lista[i]=rd_lista[i]/1000000
      rd_lista[i]=round(rd_lista[i])
      rd_lista[i]=str(rd_lista[i])+" M"



rd_cockpit=Dp.worksheet('COCKPIT MENSAL')

arrayrd=np.array(df_rd)

pori=[1]
for sts in pori:
  rd_cockpit.update('AA31', arrayrd.tolist())

# for cel in E2E_plas:
#   cock.update('G29', arrayE2E.tolist())

rd_dese=[rd_chey_dp,rd_fernanda_dp,rd_flavia_oliveira_dp,rd_flavia_guedes_dp]

rd_dese=[rd_chey_dp,rd_fernanda_dp,rd_flavia_oliveira_dp,rd_flavia_guedes_dp]
ori=''
fer=''
fla_o=''
fla_g=''
if rd_chey_dp<=0.5:     #
  ori='\U0001F534'      #
if 0.5< rd_chey_dp<=0.8:#
  ori='\U0001F7E1'      #
if rd_chey_dp>0.8:      #
  ori='\U0001F7E2'      #
#########################
if rd_fernanda_dp<=0.5:     #
  fer='\U0001F534'          #
if 0.5< rd_fernanda_dp<=0.8:#
  fer='\U0001F7E1'          #
if rd_fernanda_dp>0.8:      #
  fer='\U0001F7E2'          #
#############################
if rd_flavia_oliveira_dp<=0.5:     #
  fla_o='\U0001F534'                 #
if 0.5< rd_flavia_oliveira_dp<=0.8:#
  fla_o='\U0001F7E1'                 #
if rd_flavia_oliveira_dp>0.8:      #
  fla_o='\U0001F7E2'                 #
####################################
if rd_flavia_guedes_dp<=0.5:     #
  fla_g='\U0001F534'               #
if 0.5< rd_flavia_guedes_dp<=0.8:#
  fla_g='\U0001F7E1'               #
if rd_flavia_guedes_dp>0.8:      #
  fla_g='\U0001F7E2'               #
##################################

# Commented out IPython magic to ensure Python compatibility.
import json
import requests
import os
#Set the webhook_url to the one provided by Slack when you create the webhook at https://my.slack.com/services/new/incoming-webhook/
webhook_url = 'https://hooks.slack.com/services/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'
if hora>="16":
  slack_data ={

    "blocks": [
      {
        "type": "header",
        "text": {
          "type": "plain_text",
          "text": "==========================================\n\t\t\t\t\t\t\t\t\t                       \t\t\t\t\t\t\t\t\tCS SALES\n==========================================",
          "emoji": True
        }
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{chey}*CHEYENNE*"
        }
      },
      {
        "type": "section",
        "fields":[
          {
            "type": "mrkdwn",
            "text": f"*META*\n{rd_lista[4]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{rd_lista[0]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{(rd_lista[5]*100).round(1)}%"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{rd_lista[9]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{ori}"
          },
          
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{fernanda_pch}*FERNANDA*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{rd_lista[4]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{rd_lista[1]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{(rd_lista[6]*100).round(1)}%"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{rd_lista[10]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{fer}"
          },
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{flavia_oli}*FLAVIA OLIVEIRA*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{rd_lista[13]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{rd_lista[2]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{(rd_lista[7]*100).round(1)}%"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{rd_lista[11]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{fla_o}"
          },
        ]
      },
      {
        "type": "divider"
      },
      {
        "type": "section",
        "text": {
          "type": "mrkdwn",
          "text": f">{flavia_guedes}*FLAVIA GUEDES*"
        }
      },
      {
        "type": "section",
        "fields": [
          {
            "type": "mrkdwn",
            "text": f"*META*\n{rd_lista[13]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*PRODUÇÃO*\n{rd_lista[3]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*DESEMPENHO*\n{(rd_lista[8]*100).round(1)}%"
          },
          {
            "type": "mrkdwn",
            "text": f"*PREVISÃO*\n{rd_lista[12]}"
          },
          {
            "type": "mrkdwn",
            "text": f"*STATUS*\n{fla_g}"
          },
        ]
      }
    ]
  }
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )
  if response.status_code != 200:
        raise ValueError(
            'Request to slack returned an error %s, the response is:\n%s'
#             % (response.status_code, response.text)
        )
  slack_data = {'text':f''}
    
  response = requests.post(
        webhook_url, data=json.dumps(slack_data),
        headers={'Content-Type': 'application/json'}
    )

"""#Funcionários Data de contratação time de marketing

"""

funcionarios_contrat[['Dia da semana','Mês','Dia','Hora','Fuso','Ano']]=funcionarios_contrat['Data de Admissão'].str.split(' ', expand=True)

funcionarios_contrat=funcionarios_contrat[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Salário Líquido','Margem Consignável','Telefone','E-mail','Perfil','Mês'	,'Dia','Ano']]

funcionarios_contrat['Data']=funcionarios_contrat['Dia']+'/'+funcionarios_contrat['Mês']+'/'+funcionarios_contrat['Ano']

funcionarios_contrat['Data']=pd.to_datetime(funcionarios_contrat['Data'],format="%d/%b/%Y", errors='coerce').apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else '')

func_e2e=funcionarios_contrat[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Margem Consignável','Telefone','E-mail','Perfil','Data']]

func_comp=funcionarios_contrat[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Margem Consignável','Telefone','E-mail','Perfil','Data']]

func_x=funcionarios_contrat[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Margem Consignável','Telefone','E-mail','Perfil','Data']]

funcionarios_fim=funcionarios_contrat.query('Grupo=="VERZANI & SANDRINI S.A." |Grupo=="VERZANI - NOVAS AQUISIÇÕES"|Grupo=="HAGANÁ" |Grupo=="ONET"')

funcionarios_levva=funcionarios_contrat.query('Grupo=="SUPERMARKET G.M.A.P" |Grupo=="SUPERMARKET PADRÃO"|Grupo=="SUPERMARKET ALVORADA"')

funcionarios_corujão=funcionarios_contrat.query('Grupo=="CORUJÃO"')

funcionarios_contrat['Grupo']=funcionarios_contrat['Grupo'].str.upper()
funcionarios_contrat=funcionarios_contrat.query('Grupo=="VERZANI & SANDRINI S.A." |Grupo=="VERZANI - NOVAS AQUISIÇÕES"|Grupo=="HAGANÁ" |Grupo=="GRUPO GR"|Grupo=="SUPERMARKET ALVORADA"')

funcionarios_contrat=funcionarios_contrat[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Salário Líquido','Margem Consignável','Telefone','E-mail','Perfil','Data']]

funcionarios_contrat=funcionarios_contrat.query('Data!=""')

data_agora=datetime.datetime.today()

funcionarios_contrat['Tempo de contratação']=pd.to_datetime(funcionarios_contrat['Data'],format="%d/%m/%Y").apply(lambda x: (data_agora-x).days)

funcionarios_contrat['Tempo de contratação']=funcionarios_contrat['Tempo de contratação'].apply(lambda x:x//30)

propostas_func=range_minmax[['CPF','Valor Total']]

func_cont=pd.merge(funcionarios_contrat,propostas_func, how='left', on='CPF')

func_cont['Valor Total']=func_cont['Valor Total'].fillna('SEM PROPOSTAS')

func_cont['Valor Total']=func_cont['Valor Total'].apply(lambda x: 'FEZ PROPOSTA' if x !="SEM PROPOSTAS" else x)

func_cont=func_cont.drop_duplicates(subset=['CPF'])

func_cont=func_cont.rename(columns={'Valor Total':'Propostas'})

func_cont=func_cont.fillna('')

func_cont=func_cont.query('`Margem Consignável`!="Não Importada"')

func_cont['Margem Consignável']=pd.to_numeric(func_cont['Margem Consignável'])

func_cont=func_cont.query('`Margem Consignável`>0')

Andamento=range_minmax.query('Status=="DONE"')

Andamento=Andamento[['CPF','Status']]

func_cont=pd.merge(func_cont,Andamento, how='left', on='CPF')

func_cont=func_cont.query('Status!="DONE"')

func_cont['E-mail']=func_cont['E-mail'].apply(lambda x: 'sem email' if '@naoinformado.com'in x else x)

func_cont['E-mail']=func_cont['E-mail'].apply(lambda x: 'sem email' if '@email.com'in x else x)

func_cont['E-mail']=func_cont['E-mail'].apply(lambda x: 'sem email' if '@mail.com'in x else x)

func_cont=func_cont.query('`E-mail`!="sem email"')

func_cont.drop(['Status'], axis=1, inplace=True)

campanha=gc.open_by_url('https://docs.google.com/spreadsheets/d/1e3zLGUuDQ-zx30UpsbwPVuPNscePVqDekyErgXgpMgU/edit#gid=0')
campanhax=campanha.worksheet('FUNCIONÁRIOS')
campanhax.clear()
campanhax.update([func_cont.columns.values.tolist()]+func_cont.values.tolist())



"""#Verzani fgts time de marketing"""

verzani_fgts=func_cont.query('Grupo=="VERZANI & SANDRINI S.A." |Grupo=="VERZANI - NOVAS AQUISIÇÕES"')

verzani_fgts['Margem Consignável']=pd.to_numeric(verzani_fgts['Margem Consignável'])
verzani_fgts['Salário Bruto']=pd.to_numeric(verzani_fgts['Salário Bruto'])

verzani_fgts_zero=verzani_fgts.query('`Margem Consignável`==0')

verzani_fgts_zero=verzani_fgts_zero.query('`Tempo de contratação`>=0')

verzani_fgts_zero['FGTS']=verzani_fgts['Salário Bruto'].apply(lambda x: x*0.08 )

verzani_fgts_zero['Valor FGTS']=verzani_fgts['Tempo de contratação'].apply(lambda x: mes if x>=12 else x)

verzani_fgts_zero['FGTS']=verzani_fgts_zero['FGTS']*verzani_fgts_zero['Valor FGTS']

verzani_fgts_zero=verzani_fgts_zero[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Salário Líquido','Margem Consignável','Telefone','E-mail','Perfil','Data','Tempo de contratação','Propostas','FGTS']]

verzani_fgts_zero=verzani_fgts_zero.fillna('')

VERZANIX=gc.open_by_url('https://docs.google.com/spreadsheets/d/1Cj2cAew2cAOwz1Q4HLW4vB-LS5LEo63hpBmBzjzRt5U/edit#gid=0')
VERZANIY=VERZANIX.worksheet('DADOS')
VERZANIY.clear()
VERZANIY.update([verzani_fgts_zero.columns.values.tolist()]+verzani_fgts_zero.values.tolist())

"""#LEVVA"""

Levva=range_minmax.query('Grupo=="SUPERMARKET G.M.A.P" |Grupo=="SUPERMARKET PADRÃO"|Grupo=="SUPERMARKET ALVORADA"')

Levva=Levva.fillna('')

levva_rp=reprov3.query('Grupo=="SUPERMARKET G.M.A.P" |Grupo=="SUPERMARKET PADRÃO"|Grupo=="SUPERMARKET ALVORADA"')

levva_rp['Grupo']=levva_rp['Grupo'].str.upper()

levva_rp=pd.merge(levva_rp,tdm, how='left', on='Motivo Reprovação')

levva_rp=levva_rp.drop(['Motivo Reprovação'], axis=1, inplace=False)

levva_rp=levva_rp.fillna('')

levva_rp['Data/Horário Reprovação']=pd.to_datetime(levva_rp['Data/Horário Reprovação'], format='%Y-%m-%d %H:%M:%S').apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else '')

funcionarios_levva=funcionarios_levva.fillna('')

levva=gc.open_by_url('https://docs.google.com/spreadsheets/d/1NY_D1nUiCodtr_cJoYv69X3aBP0GPtqItPAeCBE_atA/edit#gid=0')
levvax=levva.worksheet('Propostas')
levvar=levva.worksheet('Reprovação')
levvac=levva.worksheet('Colaboradores')
cell_list = levvax.range("A1:L10000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
levvax.update_cells(cell_list)
levvar.clear()
levvac.clear()
levvax.update([Levva.columns.values.tolist()]+Levva.values.tolist())
levvar.update([levva_rp.columns.values.tolist()]+levva_rp.values.tolist())
levvac.update([funcionarios_levva.columns.values.tolist()]+funcionarios_levva.values.tolist())

"""#CORUJÃO"""

corujão=range_minmax.query('Grupo=="CORUJÃO"')

corujão=corujão.fillna('')

reprov3['Grupo']=reprov3['Grupo'].str.upper()

corujão_rp=reprov3.query('Grupo=="CORUJÃO"')

corujão_rp=pd.merge(corujão_rp,tdm, how='left', on='Motivo Reprovação')

corujão_rp=corujão_rp.drop(['Motivo Reprovação'], axis=1, inplace=False)

corujão_rp=corujão_rp.fillna('')

corujão_rp['Data/Horário Reprovação']=pd.to_datetime(corujão_rp['Data/Horário Reprovação'], format='%Y-%m-%d %H:%M:%S').apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else '')

funcionarios_corujão=funcionarios_corujão.fillna('')

coru=gc.open_by_url('https://docs.google.com/spreadsheets/d/1vP-IkVAudWTaA8pb7eQhbqaKvy3eOBHs7VQEWoxJ6XE/edit#gid=2118563315')
corujãox=coru.worksheet('Propostas')
corujãor=coru.worksheet('Reprovação')
corujãoc=coru.worksheet('Colaboradores')
cell_list = corujãox.range("A1:L10000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
corujãox.update_cells(cell_list)
corujãor.clear()
corujãoc.clear()
corujãox.update([corujão.columns.values.tolist()]+corujão.values.tolist())
corujãor.update([corujão_rp.columns.values.tolist()]+corujão_rp.values.tolist())
corujãoc.update([funcionarios_corujão.columns.values.tolist()]+funcionarios_corujão.values.tolist())

"""#AO3

"""

ao3=range_minmax.query('Grupo=="AO3"')

ao3=ao3.fillna('')

reprov3['Grupo']=reprov3['Grupo'].str.upper()

ao3_rp=reprov3.query('Grupo=="AO3"')

ao3_rp=pd.merge(ao3_rp,tdm, how='left', on='Motivo Reprovação')

ao3_rp=ao3_rp.drop(['Motivo Reprovação'], axis=1, inplace=False)

ao3_rp=ao3_rp.fillna('')

ao3_rp['Data/Horário Reprovação']=pd.to_datetime(ao3_rp['Data/Horário Reprovação'], format='%Y-%m-%d %H:%M:%S').apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else '')

funcionarios_total['Grupo']=funcionarios_total['Grupo'].str.upper()

funcionarios_ao3=funcionarios_total.query('Grupo=="AO3"').fillna('')



ao3x=gc.open_by_url('https://docs.google.com/spreadsheets/d/1fDAw2_N1zOCbbbN_T4JwY3IV3-YBnUJUboC3aDYkSkg/edit#gid=0')
ao3prop=ao3x.worksheet('Propostas')
ao3repro=ao3x.worksheet('Reprovação')
ao3cola=ao3x.worksheet('Colaboradores')
ao3cola.clear()
ao3prop.update([ao3.columns.values.tolist()]+ao3.values.tolist())
ao3repro.update([ao3_rp.columns.values.tolist()]+ao3_rp.values.tolist())
ao3cola.update([funcionarios_ao3.columns.values.tolist()]+funcionarios_ao3.values.tolist())

"""#Cargo funcionários

"""

caminho10='/content/drive/Othercomputers/Meu laptop/FUNÇÃO DO FUNCIONÁRIO'
lista_arquivos10= os.listdir(caminho10)
lista_datas10= []
for arquivo in lista_arquivos10:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho10}/{arquivo}")
  lista_datas10.append((data, arquivo))

lista_datas10.sort(reverse=True)
ultimo_arquivo10= lista_datas10[0]
arquivo10=ultimo_arquivo10[1]

cargo=pd.read_csv((f"{caminho10}/{arquivo10}"),dtype={'CNPJ': str,'CPF': str})

Aniversario=cargo[['cpf','birthdayDate']]

Nascimento=cargo[['cpf','birthdayDate','name']]

Nascimento['birthdayDate']=pd.to_datetime(Nascimento['birthdayDate'], format='%Y-%m-%d', errors='coerce')

Nascimento['Idade']=Nascimento['birthdayDate'].apply(lambda x: (data_agora-x).days if not pd.isnull(x) else x )

Nascimento['Idade']=Nascimento['Idade']//365

Nascimento['Idade']=Nascimento['Idade'].fillna('')

Nascimento=Nascimento.query('Idade!=""')

Nascimento.to_excel('Nascimento.xlsx')

cargo=cargo[['cpf','company_jobrole']]

def substituir(x):
  x=x.replace('.',"").replace('-',"")
  return x

func_e2e['CPF']=func_e2e['CPF'].apply(substituir)

func_e2e['Grupo']=func_e2e['Grupo'].str.upper()
func_e2e=pd.merge(func_e2e,ADE, how='left', on='Grupo')

func_e2e=func_e2e.query('`Modelo de Negócio`=="End to End"')

cargo=cargo.rename(columns={'cpf':'CPF','company_jobrole':'Cargo'})

func_e2e=pd.merge(func_e2e,cargo,how='left', on='CPF')

func_e2e=func_e2e.fillna('')

"""#Analisar Campanhas"""

Analise_Refin=Analise_Refin[['Margem Consignável','CNPJ','Grupo','CPF','Data da Solicitação','Valor Total']]

func_comp=func_comp[['CPF','Data','Telefone','E-mail']]

Analise_Refin=pd.merge(Analise_Refin,func_comp,how='left',on='CPF' )

tempo=tempo[['CPF','Status']]

Analise_Refin=pd.merge(Analise_Refin,tempo, how='left', on='CPF')

Analise_Refin=Analise_Refin.query('Status!="DONE"')

Analise_Refin['CONTRATAÇÃO']=pd.to_datetime(Analise_Refin['Data'],format='%d/%m/%Y', errors='coerce').apply(lambda x:(data_agora-x).days if not pd.isnull(x) else x)

Analise_Refin['CONTRATAÇÃO']=Analise_Refin['CONTRATAÇÃO']//30

Analise_Refin=Analise_Refin.query('`CONTRATAÇÃO`>=6')

Analise_Refin=Analise_Refin[['Margem Consignável','CNPJ','Grupo','CPF','Data da Solicitação','Data','Telefone','CONTRATAÇÃO','E-mail']]

Analise_Refin['Grupo']=Analise_Refin['Grupo'].str.upper()

Analise_Refin=pd.merge(Analise_Refin,ADE, how='left', on ="Grupo")

Analise_Refin=Analise_Refin.query('`Modelo de Negócio`!="SaaS"')

Analise_Refin.to_excel('Refin.xlsx')

funcionarios_fim=funcionarios_fim.query('`Margem Consignável`!="Não Importada"')
funcionarios_fim['Margem Consignável']=pd.to_numeric(funcionarios_fim['Margem Consignável'])
funcionarios_fim=funcionarios_fim.query('`Margem Consignável`>0')

done_fim=range_minmax[['CPF','Status']]

funcionarios_fim=funcionarios_fim[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Margem Consignável','Telefone','E-mail','Data']]

funcionarios_fim['Telefone']=pd.Series(funcionarios_fim['Telefone'], dtype='string')

funcionarios_fim['Telefone']=funcionarios_fim['Telefone'].fillna('')

funcionarios_fim['Telefone']=funcionarios_fim['Telefone'].apply(lambda x: 'sem número' if '999999' in x else x)

funcionarios_fim=funcionarios_fim.query('Telefone!="sem número"')

funcionarios_fim=funcionarios_fim.query('Telefone!=""')

funcionarios_fim=funcionarios_fim.query('Telefone!=" "')

funcionarios_fim=funcionarios_fim.fillna('')

funcionarios_fim_prop=pd.merge(funcionarios_fim,done_fim, how='left', on='CPF')

funcionarios_fim_prop['Status']=funcionarios_fim_prop['Status'].fillna('')

funcionarios_fim_prop=funcionarios_fim_prop.query('Status=="DONE"')

funcionarios_fim_prop=funcionarios_fim_prop.drop_duplicates(subset='CPF')

funcionarios_sem_emprestimo=pd.merge(funcionarios_fim,done_fim, how='left', on='CPF')

funcionarios_sem_emprestimo['Status']=funcionarios_sem_emprestimo['Status'].fillna('')

funcionarios_sem_emprestimo=funcionarios_sem_emprestimo.query('Status!=""')

funcionarios_sem_emprestimo=funcionarios_sem_emprestimo.drop_duplicates(subset='CPF')

funcionarios_fim.to_excel('Base_mergem.xlsx')

funcionarios_fim_prop.to_excel('Funcionários_com_emprestimo.xlsx')

funcionarios_sem_emprestimo.to_excel('Fizeram_emprestimo.xlsx')

"""#TESTAR BASES"""

verzani_func=funcionarios_contrat.query('Grupo=="VERZANI & SANDRINI S.A."')

verzani_func.to_excel('verzani.xlsx')

pendente=range_minmax.query('Status=="SIGNATURE_PENDING"')

pendente=pd.merge(pendente,func_comp,how='left', on='CPF')

pendente.to_excel('pendente.xlsx')

"""#FGTS END TO END"""

range_minmax['Grupo']=range_minmax['Grupo'].str.upper()
FGTS_end=pd.merge(range_minmax,ADE,how='left', on='Grupo')

FGTS_end=FGTS_end.query('`Modelo de Negócio`=="End to End"')

FGTS_end=FGTS_end[['NomeNegocio','Nome','CPF','Data da Solicitação','CNPJ','Grupo']]

FGTS_end=pd.merge(FGTS_end,func_comp,how='left',on='CPF')

FGTS_end['Tempo de contratação em meses']=pd.to_datetime(FGTS_end['Data'],format='%d/%m/%Y', errors='coerce').apply(lambda x:(data_agora-x).days if not pd.isnull(x) else x)

FGTS_end['Tempo de contratação em meses']=FGTS_end['Tempo de contratação em meses']//30

FGTS_end=FGTS_end.fillna('')

FGTS_end.to_excel('FGTS_E2E.xlsx')

"""#Produção de todas as Empresas Dsde sempre"""

Total_geral=pea[['Grupo','NomeNegocio','CNPJ','CPF NORMALIZADO','Valor Total','Status','Salário Bruto','Data de Pagamento','Data da Solicitação']]

Total_geral['DONE R$']=Total_geral.loc[(Total_geral['Status']=="DONE"),['Valor Total']]
Total_geral['PAID R$']=Total_geral.loc[(Total_geral['Status']=="PAID"),['Valor Total']]
# Total_geral['DONE R$']=Total_geral

Total_geral['PAID E DONE R$']=Total_geral['PAID R$'].fillna(0)+Total_geral['DONE R$'].fillna(0)

Total_geral['DONE']=Total_geral.loc[(Total_geral['Status']=="DONE"),['CPF NORMALIZADO']]
Total_geral['PAID']=Total_geral.loc[(Total_geral['Status']=="PAID"),['CPF NORMALIZADO']]

Total_geral['PAID E DONE']=Total_geral['PAID'].fillna(0)+Total_geral['DONE'].fillna(0)

Total_geral['Data de Pagamento']=pd.to_datetime(Total_geral['Data de Pagamento'], format="%d/%m/%Y",errors='coerce').apply(lambda x: datetime.datetime.strftime(x,"%m/%Y") if not pd.isnull(x) else x)

Total_geral['Data da Solicitação']=pd.to_datetime(Total_geral['Data da Solicitação'], format="%d/%m/%Y",errors='coerce').apply(lambda x: datetime.datetime.strftime(x,"%m/%Y") if not pd.isnull(x) else x)

Total_geral[mes_anterior1]=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior1),['PAID E DONE']]
Total_geral[mes_anterior2]=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior2),['PAID E DONE']]
Total_geral[mes_anterior3]=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior3),['PAID E DONE']]

Total_geral['m1']=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior1),['PAID E DONE R$']]
Total_geral['m2']=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior2),['PAID E DONE R$']]
Total_geral['m3']=Total_geral.loc[(Total_geral['Data de Pagamento']==mes_anterior3),['PAID E DONE R$']]

Total_geral['S1']=Total_geral.loc[(Total_geral['Data da Solicitação']==mes_anterior1),['CPF NORMALIZADO']]
Total_geral['S2']=Total_geral.loc[(Total_geral['Data da Solicitação']==mes_anterior2),['CPF NORMALIZADO']]
Total_geral['S3']=Total_geral.loc[(Total_geral['Data da Solicitação']==mes_anterior3),['CPF NORMALIZADO']]

Total_geral['PROPOSTAS SOLICITADAS 3 MESES']=Total_geral['S1'].fillna(0)+Total_geral['S2'].fillna(0)+Total_geral['S3'].fillna(0)

Total_geral['Propostas 3 meses R$']=Total_geral['m1'].fillna(0)+Total_geral['m2'].fillna(0)+Total_geral['m3'].fillna(0)

Total_geral['Propostas últimos 3 meses']=Total_geral[mes_anterior1].fillna(0)+Total_geral[mes_anterior2].fillna(0)+Total_geral[mes_anterior3].fillna(0)

Total_geral=Total_geral.groupby(['Grupo']).agg({'PAID E DONE R$':'sum','PAID E DONE':'sum','CPF NORMALIZADO':'sum','Valor Total':'sum','Salário Bruto':'mean','Propostas últimos 3 meses':'sum','Propostas 3 meses R$':'sum','PROPOSTAS SOLICITADAS 3 MESES':'sum'}).reset_index()

Total_geral=Total_geral.rename(columns={'CPF NORMALIZADO':'QUANTIDADE SOLICITADA','Valor Total':'VALOR TOTAL SOLICITADO','PAID E DONE R$':'VALOR PAGO','PAID E DONE':'QUANTIDADE PAGA','Salário Bruto':'SALARIO MEDIO'})

Total_geral['Grupo']=Total_geral['Grupo'].str.upper()

qppa=Dp.worksheet('PAGOS DESDE O INICIO DA PAKETÁ')
cell_list = qppa.range("A1:G5000")
# Set the value
for cell in cell_list:
    cell.value = ''

# Update in batch
qppa.update_cells(cell_list)
qppa.update([Total_geral.columns.values.tolist()] + Total_geral.values.tolist())
# Set the value

x=pd.read_excel('/content/drive/MyDrive/VERZANI_TELEFONES_PAKETÁ.xlsx',dtype={'CPF': str})

# x['Telefone Residencia DDD']=pd.Series(x['DDD Telefone'],dtype="string")+pd.Series(x['TelefoneResidencia'],dtype="string")

# x['Telefone Residencia DDD']=x['Telefone Residencia DDD'].apply(lambda x: x.replace("-","") if not pd.isnull(x) else x )

# x['Telefone Residencia DDD']=x['Telefone Residencia DDD'].apply(lambda x: x.replace(")","").replace("+","").replace("(","").replace("_","").replace(" ","")  if not pd.isnull(x) else x )

# x['Telefone Residencia DDD']=x['Telefone Residencia DDD'].apply(lambda x: x[0:13] if not pd.isnull(x) else x)

# x['Telefone Residencia DDD']=x['Telefone Residencia DDD'].apply(lambda x: re.sub('[^0-9]', '', x) if not pd.isnull(x) else x)

x['TelefoneCelular']=pd.Series(x['TelefoneCelular'],dtype="string").apply(lambda x: re.sub('[^0-9]', '', x) if not pd.isnull(x) else x)

def regular(x):
  if len(x)>9:
    x=x[2:]
  return x

x['TelefoneCelular']=x['TelefoneCelular'].apply(regular)

x['TelefoneCelular']=pd.Series(x['DDD Celular'],dtype='string')+x['TelefoneCelular']

x.to_excel('Verzani_celular.xlsx')

"""# ***#ANALISE LISTAS***

"""

func_x['Tempo de Contratção']=pd.to_datetime(func_x['Data'],format="%d/%m/%Y", errors='coerce').apply(lambda x: (data_agora-x).days if not pd.isnull(x) else x)

func_x['Tempo de Contratção']=func_x['Tempo de Contratção']//30

func_x=func_x[['CPF','Salário Bruto','Tempo de Contratção']]

analise_end=analise_date.query('`Modelo de negócio`=="E2E"')

analise_end=analise_end.query('Status=="CANCELED" | Status=="REJECTED_PAKETA"| Status=="REJECTED_RH"')

analise_end['Data da Solicitação']=pd.to_datetime(analise_end['Data da Solicitação'],format="%d/%m/%Y")

analise_end=analise_end.query('`Data da Solicitação`>="2022-07-01"')

faturamento=analise_end[['Grupo','Valor Total','Nome','Taxa (%)','CPF']]

faturamento=faturamento.sort_values(by=['Taxa (%)','Nome'], ascending=True)



rfat=reprov3[['Motivo Reprovação','CPF Tomador','Comentário Reprovação','Valor Total','Modelo de Negocio','Grupo']]

rfat=rfat.rename(columns={'CPF Tomador':'CPF'})

rfat=rfat.query('`Modelo de Negocio`=="E2E"')

rfat=pd.merge(faturamento,rfat,how='left',on='CPF')

rfat

testex=rfat[['CPF','Motivo Reprovação','Taxa (%)','Valor Total_x']].groupby(['Motivo Reprovação','Taxa (%)','Valor Total_x']).agg({'CPF':'count'}).reset_index()

testex=testex.sort_values(by=['Taxa (%)'], ascending=False)
testex=pd.merge(testex,tdm,how='left',on='Motivo Reprovação')

testex['Taxa (%)'].mean()

0.03491055900621118

w=testex.query('`Taxa (%)`>0.03491055900621118')

w

w.sum()

reprov3['Data/Horário Reprovação']=pd.to_datetime(reprov3['Data/Horário Reprovação']).apply(lambda x: datetime.datetime.strftime(x,"%Y-%m-%d") if not pd.isnull(x) else x )

reprov3['Data/Horário Reprovação']=pd.to_datetime(reprov3['Data/Horário Reprovação'],format="%Y-%m-%d")

analise_verzi=reprov3.query(' Grupo=="HAGANÁ" ')

D=analise_verzi[['CPF Tomador','Motivo Reprovação','Grupo','Valor Total','Comentário Reprovação','Data/Horário Reprovação']].groupby(['Motivo Reprovação','Data/Horário Reprovação']).agg({'CPF Tomador':'count','Valor Total':'sum'}).reset_index()

D=D.sort_values(by=['CPF Tomador'], ascending=False)

M=D.query('`Data/Horário Reprovação`>="2022-07-01"')

M=M.groupby('Motivo Reprovação').agg({'Valor Total':'sum'}).reset_index()

M=pd.merge(M,tdm,how='left',on='Motivo Reprovação')

M.query("Traduzido in['CLIENTE SEM LIMITE DISPONÍVEL','VALOR SOLICITADO ACIMA DO DISPONÍVEL','SEM MARGEM CONSIGNÁVEL'] ").sum()

f=pd.merge(D,tdm,how='left',on='Motivo Reprovação')

f.query("Traduzido in['CLIENTE SEM LIMITE DISPONÍVEL','VALOR SOLICITADO ACIMA DO DISPONÍVEL'] ").sum()

rt=['CLIENTE NÃO ENVIOU INFORMAÇÕES FINAIS','O CLIENTE DESISTIU DA PROPOSTA','VALOR SOLICITADO ACIMA DO DISPONÍVEL','SEM CONTATO COM CLIENTE','CLIENTE NÃO ELEGÍVEL - FAIXA ETÁRIA','DADOS INCORRETOS','AJUSTAR VALOR DA PROPOSTA DE EMPRÉSTIMO','AJUSTAR DADOS PESSOAIS','VALOR SOLICITADO ACIMA DO DISPONÍVEL','PROCESSO DE EMPRÉSTIMO LENTO','AJUSTAR DADOS BANCÁRIOS']

# def calc_juros_compostos(principal, periodo, juros): 
#     """ CALCULADORA DE JUROS COMPOSTOS """
#     montante = principal * ((1 + juros)**periodo)
#     juros = montante-principal
#     delta_e2e['Taxa Total']=montante
# calc_juros_compostos(delta_e2e['Valor Total'],delta_e2e['Nº de parcelas'],delta_e2e['Taxa (%)'])

import seaborn as sb

"""#REPROVAÇÃO POR IDADE"""

idade=pd.merge(reprov3,tdm,how='left',on='Motivo Reprovação')

idade_x=idade.query('Traduzido=="CLIENTE NÃO ELEGÍVEL - FAIXA ETÁRIA"')

idade_x['Ano']=idade_x['Data/Horário Reprovação'].apply(lambda x: datetime.datetime.strftime(x,"%Y") if not pd.isnull(x) else x )
idade_x['Ano']=pd.to_numeric(idade_x['Ano'])
idade_x=idade_x.query('Ano==@ano')

Aniversario=Aniversario.rename(columns={'cpf':'CPF Tomador'})

idade_x=idade_x[['Grupo','NomeNegocio','Comentário Reprovação','Valor Total','Telefone','Traduzido','E-mail','CPF Tomador','Usuário que Reprovou']]

idade_x.to_excel('Reprovados por idade.xlsx')



"""#INICIO DO CONTRATO + EMPRESTIMOS ATIVOS POR GRUPO

"""

empxx=empx.groupby(['paketa_groups → name']).agg({'createdAt':'min'}).reset_index()

empxx['createdAt']=empxx['createdAt'].apply(lambda x: datetime.datetime.strftime(x, "%d/%m/%Y") if not pd.isnull(x) else x)

empxx=empxx.rename(columns={'paketa_groups → name':'Grupo'})
empxx=empxx.rename(columns={'createdAt':'Data de inicio'})

empxx['Grupo']=empxx['Grupo'].str.upper()

INICIO_EMP=Dp.worksheet('INCIO DA EMPRESA')
INICIO_EMP.update([empxx.columns.values.tolist()]+empxx.values.tolist())

range_minmax['Status']=range_minmax['Status'].str.upper()
contratos_ativos=range_minmax.query('Status=="DONE"')

contratos_ativos=contratos_ativos.groupby(['Grupo','NomeNegocio']).agg({'CPF':'count','Valor Total':'sum'}).reset_index()

contratos_atv=Dp.worksheet('EMPRESTIMOS ATIVOS PRO GRUPO')
contratos_atv.update([contratos_ativos.columns.values.tolist()]+contratos_ativos.values.tolist())

"""#REFIM"""

caminho10='/content/drive/Othercomputers/Meu laptop/REFIM'
lista_arquivos10= os.listdir(caminho10)
lista_datas10= []
for arquivo in lista_arquivos10:
  #descobrir data do arquivo
  data=os.path.getmtime(f"{caminho10}/{arquivo}")
  lista_datas10.append((data, arquivo))

lista_datas10.sort(reverse=True)
ultimo_arquivo10= lista_datas10[0]
arquivo10=ultimo_arquivo10[1]

refim=pd.read_excel((f"{caminho10}/{arquivo10}"))

analise_refim=analise_date[['Grupo','CPF','CCB','Data de Pagamento']]

refim=refim.rename(columns={'Nº CCB':'CCB'})

refimx=pd.merge(refim,analise_refim,how='left',on='CCB')

refimx['Status']=refimx['Status'].str.upper()

refimx=refimx.query('Status=="DONE"')

refimx=refimx[['CCB','Status','Valor Refinan','name','Grupo','CPF','Data de Pagamento']]

refimx=refimx.groupby(['Grupo','name','CCB','Data de Pagamento','CPF']).agg({'Status':'count','Valor Refinan':'sum'}).reset_index()

refimx=refimx.rename(columns={'Status':'Quantidade refinanciada','name':'Nome'})

refim_atv=Dp.worksheet('REFIM')
refim_atv.update([refimx.columns.values.tolist()]+refimx.values.tolist())

"""#**SALÁRIOS ACIMA DE 5000, 10000, 20000**

##SALÁRIOS ALTOS
"""

funcionarios_total=funcionarios_total[['Empresa','Grupo','CNPJ','Nome','CPF','Salário Bruto','Telefone','E-mail','Data','Margem Consignável']]

contratx=range_minmax[['CPF','Status']]

contratx=contratx.query('Status=="DONE" | Status=="PAID"')

funcionarios_5000=funcionarios_total.query('`Salário Bruto`>=5000 & `Salário Bruto`<10000')

funcionarios_10000=funcionarios_total.query('`Salário Bruto`>=10000 & `Salário Bruto`<20000')

funcionarios_20000=funcionarios_total.query('`Salário Bruto`>=20000')

"""##5000"""

funcionarios_5000=pd.merge(funcionarios_5000,contratx,how='left',on='CPF')

funcionarios_5000['Status']=funcionarios_5000['Status'].fillna('')

funcionarios_5000_sem=funcionarios_5000.query('Status==""')

funcionarios_5000_sem=funcionarios_5000_sem.fillna('')

"""##10000"""

funcionarios_10000=pd.merge(funcionarios_10000,contratx,how='left',on='CPF')

funcionarios_10000['Status']=funcionarios_10000['Status'].fillna('')

funcionarios_10000_sem=funcionarios_10000.query('Status==""')

funcionarios_10000_sem=funcionarios_10000_sem.fillna('')

"""##20000"""

funcionarios_20000=pd.merge(funcionarios_20000,contratx,how='left',on='CPF')

funcionarios_20000['Status']=funcionarios_20000['Status'].fillna('')

funcionarios_20000_sem=funcionarios_20000.query('Status==""')

funcionarios_20000_sem=funcionarios_20000_sem.fillna('')

"""##ENVIAR"""

valores_altos=gc.open_by_url("https://docs.google.com/spreadsheets/d/14M8gFCU0KIhZwxg7g1XU-ru_TAe5AuJMgJwkjCaVfpg/edit#gid=654956942")
valores_altos_acima_5000=valores_altos.worksheet('5000')
valores_altos_acima_10000=valores_altos.worksheet('10000')
valores_altos_acima_20000=valores_altos.worksheet('20000')
valores_altos_acima_5000.clear()
valores_altos_acima_10000.clear()
valores_altos_acima_20000.clear()

valores_altos_acima_5000.update([funcionarios_5000_sem.columns.values.tolist()]+funcionarios_5000_sem.values.tolist())
valores_altos_acima_10000.update([funcionarios_10000_sem.columns.values.tolist()]+funcionarios_10000_sem.values.tolist())
valores_altos_acima_20000.update([funcionarios_20000_sem.columns.values.tolist()]+funcionarios_20000_sem.values.tolist())



